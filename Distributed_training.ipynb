{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distributed_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FohCev-137Wv",
        "colab_type": "text"
      },
      "source": [
        "#1. Distributed training with Keras\n",
        "\n",
        "API provides an abstraction for distributing your training across multiple processing units. The goal is to allow users to enable distributed training using existing models and training code, with minimal changes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPExf5--3jnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f322db3f-c33d-4912-997f-71a31d2a4502"
      },
      "source": [
        "!pip install -q tf-nightly\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 519.0MB 31kB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 39.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 39.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oPjiFiJ5eDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7a49cf9-cd37-4efd-c7fb-8d3161eab652"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-dev20200419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2wxTkDA5zFk",
        "colab_type": "text"
      },
      "source": [
        "##1.1. Download the dataset\n",
        "\n",
        "Setting with_info to True includes the medadata for the entiredataset, which is being saved here to info. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5UFKr045h4p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "5088c699-d675-4b9b-8957-d58934e51983"
      },
      "source": [
        "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to /root/tensorflow_datasets/mnist/3.0.0...\u001b[0m\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um_k-u_W6UKT",
        "colab_type": "text"
      },
      "source": [
        "##1.2. Define distribution strategy\n",
        "\n",
        "Create a MirroredStrategy object. This will handle distribution, and provides a context manager to build your model inside."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgNHIGYH6RNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "997e9356-9b6f-4bfe-83c7-3cda7663de0c"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8lpI7Nr6t7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2694b553-1ffa-4c1e-d1de-0cc3af675163"
      },
      "source": [
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWV38yMI624y",
        "colab_type": "text"
      },
      "source": [
        "##1.3. Setup input pipeline\n",
        "\n",
        "When training a model with multiple GPUs, you can use the extra computing power effectively by increasing the batch size. In general, use the largest batch size that fits the GPU memory, and tune the learning rate accordingly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kure8Rbi60A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can also do info.splits.total_num_examples to get the total\n",
        "# number of examples in the dataset.\n",
        "\n",
        "num_train_examples = info.splits['train'].num_examples\n",
        "num_test_examples = info.splits['test'].num_examples\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8wq6gvB75OM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pixel values, which are 0-255, have to be normalized to the 0-1 range\n",
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "  \n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esugZLUr85T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply this function to the training and test data. \n",
        "# shuffle the training data, and batch it for training. \n",
        "# Notice we are alos keeping an in-memory cache of the training data to improve performance.\n",
        "\n",
        "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgWmRw1m9x03",
        "colab_type": "text"
      },
      "source": [
        "##1.4. Create the model\n",
        "\n",
        "Create and compile the Keras model in the context of strategy.scope"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS4jIY2n9wby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TThViyee-B-d",
        "colab_type": "text"
      },
      "source": [
        "##1.5. Define the callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvei3pSJ-Aat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the checkpoint directory to store the checkpoints\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x8_Py-H-L87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for decaying the learning rate.\n",
        "# You can define any decay function you need.\n",
        "def decay(epoch):\n",
        "  if epoch < 3:\n",
        "    return 1e-3\n",
        "  elif epoch >= 3 and epoch < 7:\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 1e-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmou36KD-S0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Callback for printing the LR at the end of each epoch.\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
        "                                                      model.optimizer.lr.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co3Uwq_x-kX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
        "                                       save_weights_only=True),\n",
        "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
        "    PrintLR()\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMuHqjcT-qnT",
        "colab_type": "text"
      },
      "source": [
        "##1.6. Train and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhdHNSZa-oe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "cf49670a-4129-4246-d78a-48b9aa18cb8d"
      },
      "source": [
        "model.fit(train_dataset, epochs=12, callbacks=callbacks)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "  1/938 [..............................] - ETA: 0s - loss: 2.2961 - accuracy: 0.1875WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1271: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1271: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "937/938 [============================>.] - ETA: 0s - loss: 0.2095 - accuracy: 0.9388\n",
            "Learning rate for epoch 1 is 0.0010000000474974513\n",
            "938/938 [==============================] - 31s 33ms/step - loss: 0.2093 - accuracy: 0.9388\n",
            "Epoch 2/12\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0658 - accuracy: 0.9806\n",
            "Learning rate for epoch 2 is 0.0010000000474974513\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0658 - accuracy: 0.9806\n",
            "Epoch 3/12\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9862\n",
            "Learning rate for epoch 3 is 0.0010000000474974513\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0460 - accuracy: 0.9862\n",
            "Epoch 4/12\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9929\n",
            "Learning rate for epoch 4 is 9.999999747378752e-05\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0251 - accuracy: 0.9929\n",
            "Epoch 5/12\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9940\n",
            "Learning rate for epoch 5 is 9.999999747378752e-05\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0219 - accuracy: 0.9940\n",
            "Epoch 6/12\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9947\n",
            "Learning rate for epoch 6 is 9.999999747378752e-05\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0200 - accuracy: 0.9947\n",
            "Epoch 7/12\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9953\n",
            "Learning rate for epoch 7 is 9.999999747378752e-05\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.0185 - accuracy: 0.9953\n",
            "Epoch 8/12\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9963\n",
            "Learning rate for epoch 8 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 0.0160 - accuracy: 0.9963\n",
            "Epoch 9/12\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9964\n",
            "Learning rate for epoch 9 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0157 - accuracy: 0.9964\n",
            "Epoch 10/12\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9964\n",
            "Learning rate for epoch 10 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 0.0155 - accuracy: 0.9964\n",
            "Epoch 11/12\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9965\n",
            "Learning rate for epoch 11 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0154 - accuracy: 0.9965\n",
            "Epoch 12/12\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9964\n",
            "Learning rate for epoch 12 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0152 - accuracy: 0.9964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcfaa33b9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XayGnOhA-wgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "495a7b8c-bc3f-4999-bcc3-7647b62533dd"
      },
      "source": [
        "# check the checkpoint directory\n",
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t     ckpt_4.data-00000-of-00001\n",
            "ckpt_10.data-00000-of-00001  ckpt_4.index\n",
            "ckpt_10.index\t\t     ckpt_5.data-00000-of-00001\n",
            "ckpt_11.data-00000-of-00001  ckpt_5.index\n",
            "ckpt_11.index\t\t     ckpt_6.data-00000-of-00001\n",
            "ckpt_12.data-00000-of-00001  ckpt_6.index\n",
            "ckpt_12.index\t\t     ckpt_7.data-00000-of-00001\n",
            "ckpt_1.data-00000-of-00001   ckpt_7.index\n",
            "ckpt_1.index\t\t     ckpt_8.data-00000-of-00001\n",
            "ckpt_2.data-00000-of-00001   ckpt_8.index\n",
            "ckpt_2.index\t\t     ckpt_9.data-00000-of-00001\n",
            "ckpt_3.data-00000-of-00001   ckpt_9.index\n",
            "ckpt_3.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9649cb___J34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "39fba44d-63d3-4d6f-b646-4150a1528cde"
      },
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
        "\n",
        "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 3s 22ms/step - loss: 0.0358 - accuracy: 0.9882\n",
            "Eval loss: 0.03579382598400116, Eval Accuracy: 0.9882000088691711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPilpRDM_QWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "cf3fdf39-2a4b-4bfd-e01e-7f2aea030c28"
      },
      "source": [
        "!tensorboard --logdir=/content/logs"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
            "    sys.exit(run_main())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/main.py\", line 75, in run_main\n",
            "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 289, in main\n",
            "    return runner(self.flags) or 0\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 305, in _run_serve_subcommand\n",
            "    server = self._make_server()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 409, in _make_server\n",
            "    self.flags, self.plugin_loaders, self.assets_zip_provider\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 183, in standard_tensorboard_wsgi\n",
            "    flags, plugin_loaders, data_provider, assets_zip_provider, multiplexer\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 272, in TensorBoardWSGIApp\n",
            "    tbplugins, flags.path_prefix, data_provider, experimental_plugins\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 345, in __init__\n",
            "    \"Duplicate plugins for name %s\" % plugin.plugin_name\n",
            "ValueError: Duplicate plugins for name projector\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x604FjTWHT2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3f151fd2-80b9-44b8-b820-3e97bf516537"
      },
      "source": [
        "ls -sh ./logs"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4.0K\n",
            "4.0K \u001b[0m\u001b[01;34mtrain\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh6EBRQZWnv5",
        "colab_type": "text"
      },
      "source": [
        "##1.7. Export to SavedModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d9dCFhoWlkd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "59655489-9c58-46f6-e105-05ac1da9a547"
      },
      "source": [
        "path = 'saved_model/'\n",
        "model.save(path, save_format='tf')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGRoHXcxWzBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "99c5588b-5ae1-439b-c4bd-3d8e7706bfbf"
      },
      "source": [
        "# Load model without strategy.scope\n",
        "unreplicated_model = tf.keras.models.load_model(path)\n",
        "\n",
        "unreplicated_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "eval_loss, eval_acc = unreplicated_model.evaluate(eval_dataset)\n",
        "\n",
        "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 3s 22ms/step - loss: 0.0358 - accuracy: 0.9882\n",
            "Eval loss: 0.03579382598400116, Eval Accuracy: 0.9882000088691711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc43XHqpW8wh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7dc725c7-9773-423a-a9bb-6729a5b29506"
      },
      "source": [
        "# Load with strategy.scope\n",
        "with strategy.scope():\n",
        "  replicated_model = tf.keras.models.load_model(path)\n",
        "  replicated_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                           optimizer=tf.keras.optimizers.Adam(),\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "  eval_loss, eval_acc = replicated_model.evaluate(eval_dataset)\n",
        "  print ('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 3s 22ms/step - loss: 0.0358 - accuracy: 0.9882\n",
            "Eval loss: 0.03579382598400116, Eval Accuracy: 0.9882000088691711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH6O-pZ1Xe34",
        "colab_type": "text"
      },
      "source": [
        "#2. Custom training with tf.distribute.Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-1PdMK4XCRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdb45d75-2492-42e3-b9d3-0a3f1dcb39bb"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "# Import TensorFlow\n",
        "!pip install -q tf-nightly\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-dev20200419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfGubpLfYCI-",
        "colab_type": "text"
      },
      "source": [
        "##2.1. Download the fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBRC_l-bX-ql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "e33bf07b-5c48-4aa6-9cd9-378bc6fd80c3"
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Adding a dimension to the array -> new shape == (28, 28, 1)\n",
        "# We are doing this because the first layer in our model is a convolutional\n",
        "# layer and it requires a 4D input (batch_size, height, width, channels).\n",
        "# batch_size dimension will be added later on.\n",
        "train_images = train_images[..., None]\n",
        "test_images = test_images[..., None]\n",
        "\n",
        "# Getting the images in [0, 1] range.\n",
        "train_images = train_images / np.float32(255)\n",
        "test_images = test_images / np.float32(255)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqZRpDpmYkf9",
        "colab_type": "text"
      },
      "source": [
        "##2.2. Create a strategy to distribute the variables and the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DImidhPYiYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "414ae84f-9f1d-4560-b658-3ce009c28744"
      },
      "source": [
        "# If the list of devices is not specified in the\n",
        "# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx3fusZRYxh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06cf6e8f-30f4-4684-dfa2-c73c2b436560"
      },
      "source": [
        "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOB801UFY4Ac",
        "colab_type": "text"
      },
      "source": [
        "##2.3. Setup input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-hyJFNSY1ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(train_images)\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA8k2_vOZln2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE) \n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE) \n",
        "\n",
        "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1PUBZYeZ596",
        "colab_type": "text"
      },
      "source": [
        "##2.4. Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnfWVy7gZ5Al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPXXbZ90aBmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a checkpoint directory to store the checkpoints.\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykHHGBZ_aGl6",
        "colab_type": "text"
      },
      "source": [
        "##2.5. Define the loss function\n",
        "\n",
        "Normally, on a single machine with 1 GPU/CPU, loss is divided by the number of examples in the batch of input. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrQjjoBgaDZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  # Set reduction to `none` so we can do the reduction afterwards and divide by\n",
        "  # global batch size.\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True,\n",
        "      reduction=tf.keras.losses.Reduction.NONE)\n",
        "  def compute_loss(labels, predictions):\n",
        "    per_example_loss = loss_object(labels, predictions)\n",
        "    return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvSL2QNPbq0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the metrics to track loss and accuracy\n",
        "with strategy.scope():\n",
        "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='train_accuracy')\n",
        "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0isTo-Brb16t",
        "colab_type": "text"
      },
      "source": [
        "##2.6. Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51eK3fUDb0LK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model, optimizer, and checkpoint must be created under `strategy.scope`.\n",
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHiAveiTcKFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(inputs):\n",
        "  images, labels = inputs\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images, training=True)\n",
        "    loss = compute_loss(labels, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_accuracy.update_state(labels, predictions)\n",
        "  return loss \n",
        "\n",
        "def test_step(inputs):\n",
        "  images, labels = inputs\n",
        "\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss.update_state(t_loss)\n",
        "  test_accuracy.update_state(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq1oZXAicMZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "be93ecb9-7bd4-42a5-e6a2-f751e7903cb1"
      },
      "source": [
        "# `run` replicates the provided computation and runs it\n",
        "# with the distributed input.\n",
        "@tf.function\n",
        "def distributed_train_step(dataset_inputs):\n",
        "  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
        "  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
        "                         axis=None)\n",
        "\n",
        "@tf.function\n",
        "def distributed_test_step(dataset_inputs):\n",
        "  return strategy.run(test_step, args=(dataset_inputs,))\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # TRAIN LOOP\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "  for x in train_dist_dataset:\n",
        "    total_loss += distributed_train_step(x)\n",
        "    num_batches += 1\n",
        "  train_loss = total_loss / num_batches\n",
        "\n",
        "  # TEST LOOP\n",
        "  for x in test_dist_dataset:\n",
        "    distributed_test_step(x)\n",
        "\n",
        "  if epoch % 2 == 0:\n",
        "    checkpoint.save(checkpoint_prefix)\n",
        "\n",
        "  template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \"\n",
        "              \"Test Accuracy: {}\")\n",
        "  print (template.format(epoch+1, train_loss,\n",
        "                         train_accuracy.result()*100, test_loss.result(),\n",
        "                         test_accuracy.result()*100))\n",
        "\n",
        "  test_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_accuracy.reset_states()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.5153678059577942, Accuracy: 81.36333465576172, Test Loss: 0.38318201899528503, Test Accuracy: 86.45999908447266\n",
            "Epoch 2, Loss: 0.3339560031890869, Accuracy: 87.94999694824219, Test Loss: 0.32745468616485596, Test Accuracy: 88.47000122070312\n",
            "Epoch 3, Loss: 0.289735347032547, Accuracy: 89.40666961669922, Test Loss: 0.3177132308483124, Test Accuracy: 88.6300048828125\n",
            "Epoch 4, Loss: 0.2589462101459503, Accuracy: 90.55332946777344, Test Loss: 0.3060314953327179, Test Accuracy: 88.80000305175781\n",
            "Epoch 5, Loss: 0.23737187683582306, Accuracy: 91.28500366210938, Test Loss: 0.2779774069786072, Test Accuracy: 89.69000244140625\n",
            "Epoch 6, Loss: 0.21620415151119232, Accuracy: 92.05166625976562, Test Loss: 0.3102119565010071, Test Accuracy: 89.11000061035156\n",
            "Epoch 7, Loss: 0.20048733055591583, Accuracy: 92.55333709716797, Test Loss: 0.25279226899147034, Test Accuracy: 91.18000030517578\n",
            "Epoch 8, Loss: 0.18413300812244415, Accuracy: 93.17666625976562, Test Loss: 0.256083607673645, Test Accuracy: 90.83000183105469\n",
            "Epoch 9, Loss: 0.17164701223373413, Accuracy: 93.57666015625, Test Loss: 0.24966789782047272, Test Accuracy: 91.37999725341797\n",
            "Epoch 10, Loss: 0.15677373111248016, Accuracy: 94.21499633789062, Test Loss: 0.2547090947628021, Test Accuracy: 91.22000122070312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETkQ4cFqdP2k",
        "colab_type": "text"
      },
      "source": [
        "##2.7. Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhoEIum-cPlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='eval_accuracy')\n",
        "\n",
        "new_model = create_model()\n",
        "new_optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SBncXWjdTNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def eval_step(images, labels):\n",
        "  predictions = new_model(images, training=False)\n",
        "  eval_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPx_HlT4da2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "987b6af8-459a-4790-ba36-75905574afa1"
      },
      "source": [
        "checkpoint = tf.train.Checkpoint(optimizer=new_optimizer, model=new_model)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "for images, labels in test_dataset:\n",
        "  eval_step(images, labels)\n",
        "\n",
        "print ('Accuracy after restoring the saved model without strategy: {}'.format(\n",
        "    eval_accuracy.result()*100))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy after restoring the saved model without strategy: 91.37999725341797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9BhUOk6dnew",
        "colab_type": "text"
      },
      "source": [
        "##2.8. Alternate ways of iterating over a dataset\n",
        "\n",
        "If you want to iterate over a given number of steps and not through the entire dataset you can create an iterator using the iter call and explicity call next on the iterator. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAUaVunkdi5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7e10554f-96f6-445b-a948-f1f3a18b8fec"
      },
      "source": [
        "# Iterating outside a tf.function\n",
        "for _ in range(EPOCHS):\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "  train_iter = iter(train_dist_dataset)\n",
        "\n",
        "  for _ in range(10):\n",
        "    total_loss += distributed_train_step(next(train_iter))\n",
        "    num_batches += 1\n",
        "  average_train_loss = total_loss / num_batches\n",
        "\n",
        "  template = (\"Epoch {}, Loss: {}, Accuracy: {}\")\n",
        "  print (template.format(epoch+1, average_train_loss, train_accuracy.result()*100))\n",
        "  train_accuracy.reset_states()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 0.16225148737430573, Accuracy: 94.21875\n",
            "Epoch 10, Loss: 0.165340855717659, Accuracy: 93.59375\n",
            "Epoch 10, Loss: 0.12995003163814545, Accuracy: 94.6875\n",
            "Epoch 10, Loss: 0.16367259621620178, Accuracy: 94.375\n",
            "Epoch 10, Loss: 0.13290463387966156, Accuracy: 95.78125\n",
            "Epoch 10, Loss: 0.12039406597614288, Accuracy: 95.78125\n",
            "Epoch 10, Loss: 0.1760627180337906, Accuracy: 93.75\n",
            "Epoch 10, Loss: 0.12315411865711212, Accuracy: 94.6875\n",
            "Epoch 10, Loss: 0.14033515751361847, Accuracy: 94.0625\n",
            "Epoch 10, Loss: 0.16444949805736542, Accuracy: 95.15625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH6uK0K2eGJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2076acc3-13f2-40ce-ea70-ec5fb13c7725"
      },
      "source": [
        "# Iterating inside a tf.function\n",
        "@tf.function\n",
        "def distributed_train_epoch(dataset):\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "  for x in dataset:\n",
        "    per_replica_losses = strategy.run(train_step, args=(x,))\n",
        "    total_loss += strategy.reduce(\n",
        "      tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "    num_batches += 1\n",
        "  return total_loss / tf.cast(num_batches, dtype=tf.float32)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss = distributed_train_epoch(train_dist_dataset)\n",
        "\n",
        "  template = (\"Epoch {}, Loss: {}, Accuracy: {}\")\n",
        "  print (template.format(epoch+1, train_loss, train_accuracy.result()*100))\n",
        "\n",
        "  train_accuracy.reset_states()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.1442921906709671, Accuracy: 94.59833526611328\n",
            "Epoch 2, Loss: 0.1308281272649765, Accuracy: 95.17499542236328\n",
            "Epoch 3, Loss: 0.12104317545890808, Accuracy: 95.57833099365234\n",
            "Epoch 4, Loss: 0.1106492206454277, Accuracy: 95.9800033569336\n",
            "Epoch 5, Loss: 0.10212011635303497, Accuracy: 96.17833709716797\n",
            "Epoch 6, Loss: 0.09471506625413895, Accuracy: 96.47666931152344\n",
            "Epoch 7, Loss: 0.0839567556977272, Accuracy: 96.86166381835938\n",
            "Epoch 8, Loss: 0.07851479202508926, Accuracy: 97.16999816894531\n",
            "Epoch 9, Loss: 0.07310765981674194, Accuracy: 97.29166412353516\n",
            "Epoch 10, Loss: 0.06589626520872116, Accuracy: 97.52166748046875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAoGJ2_RenMY",
        "colab_type": "text"
      },
      "source": [
        "##2.9. Tracking training loss across replicas\n",
        "\n",
        "We do not recommend using tf.metrics.Mean to track the training loss across different replicas, because of the loss scaling computation that is carried out. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Fa7VKqnfTF1",
        "colab_type": "text"
      },
      "source": [
        "#3. Multi-worker training with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQWqXtAqekXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7c2abd20-122d-4de1-d591-b6be0fafa736"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -q tf-nightly\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 519.0MB 33kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 25.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 43.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odan9rTCfi6r",
        "colab_type": "text"
      },
      "source": [
        "##3.1. Preparing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezEuI_mPfhSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "1b88a637-7db4-4027-949d-11b480203cfa"
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def make_datasets_unbatched():\n",
        "  # Scaling MNIST data from (0, 255] to (0., 1.]\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "    return image, label\n",
        "\n",
        "  datasets, info = tfds.load(name='mnist',\n",
        "                            with_info=True,\n",
        "                            as_supervised=True)\n",
        "\n",
        "  return datasets['train'].map(scale).cache().shuffle(BUFFER_SIZE)\n",
        "\n",
        "train_datasets = make_datasets_unbatched().batch(BATCH_SIZE)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to /root/tensorflow_datasets/mnist/3.0.0...\u001b[0m\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GjcOYCEfsHl",
        "colab_type": "text"
      },
      "source": [
        "##3.2. Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD3-z6Elfpzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_and_compile_cnn_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "      metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqshbkkRgrJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a05d518b-223f-4938-d3f2-5be9d8a681b5"
      },
      "source": [
        "single_worker_model = build_and_compile_cnn_model()\n",
        "single_worker_model.fit(x=train_datasets, epochs=3, steps_per_epoch=5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2879 - accuracy: 0.1063\n",
            "Epoch 2/3\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.2889 - accuracy: 0.0844\n",
            "Epoch 3/3\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.2846 - accuracy: 0.0906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f97801d7f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIG5Z8Mghovn",
        "colab_type": "text"
      },
      "source": [
        "###3.2.1. Multi-worker Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTvDqZbLhZuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['TF_CONFIG'] = json.dumps({\n",
        "    'cluster': {\n",
        "        'worker': [\"localhost:12345\", \"localhost:23456\"]\n",
        "    },\n",
        "    'task': {'type': 'worker', 'index': 0}\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk2B_OEni9Fz",
        "colab_type": "text"
      },
      "source": [
        "##3.3. Choose the right strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS02VFDah49m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "726302df-cd1b-41c2-a580-cf08505e3a9a"
      },
      "source": [
        "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/device:GPU:0',)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CollectiveCommunication.AUTO\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CollectiveCommunication.AUTO\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnP7iAWrjVmi",
        "colab_type": "text"
      },
      "source": [
        "##3.4. Train the model with MultiWorkerMirroredStrategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc7Qt_3tjO04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d9dbcbd6-3cd7-4c7b-caad-e5338038cae1"
      },
      "source": [
        "NUM_WORKERS = 2\n",
        "# Here the batch size scales up by number of workers since \n",
        "# `tf.data.Dataset.batch` expects the global batch size. Previously we used 64, \n",
        "# and now this becomes 128.\n",
        "GLOBAL_BATCH_SIZE = 64 * NUM_WORKERS\n",
        "\n",
        "# Creation of dataset needs to be after MultiWorkerMirroredStrategy object\n",
        "# is instantiated.\n",
        "train_datasets = make_datasets_unbatched().batch(GLOBAL_BATCH_SIZE)\n",
        "with strategy.scope():\n",
        "  # Model building/compiling need to be within `strategy.scope()`.\n",
        "  multi_worker_model = build_and_compile_cnn_model()\n",
        "\n",
        "# Keras' `model.fit()` trains the model with specified number of epochs and\n",
        "# number of steps per epoch. Note that the numbers here are for demonstration\n",
        "# purposes only and may not sufficiently produce a model with good quality.\n",
        "multi_worker_model.fit(x=train_datasets, epochs=3, steps_per_epoch=5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.2897 - accuracy: 0.1125\n",
            "Epoch 2/3\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 2.2823 - accuracy: 0.1172\n",
            "Epoch 3/3\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 2.2878 - accuracy: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f976bfab358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIVeeiTmjk8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset sharding and batch size\n",
        "# In multi-worker training, sharding data into multiple parts is needed to \n",
        "# ensure convergence and performance. \n",
        "\n",
        "options = tf.data.Options()\n",
        "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
        "train_datasets_no_auto_shard = train_datasets.with_options(options)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYfzIZ5yk5FI",
        "colab_type": "text"
      },
      "source": [
        "##3.5. Fault tolerance\n",
        "\n",
        "ModelCheckpoint callback:\n",
        "\n",
        "In synchronous training, the cluster would fail if one of the workers fails and no failure-recovery mechanism exists. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Mkn0Vvk4Ot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "d101178e-2d3f-4ef2-cb49-b4acce4be425"
      },
      "source": [
        "# Replace the `filepath` argument with a path in the file system\n",
        "# accessible by all workers.\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='/tmp/keras-ckpt')]\n",
        "with strategy.scope():\n",
        "  multi_worker_model = build_and_compile_cnn_model()\n",
        "multi_worker_model.fit(x=train_datasets,\n",
        "                       epochs=3,\n",
        "                       steps_per_epoch=5,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.3122 - accuracy: 0.0922INFO:tensorflow:Assets written to: /tmp/keras-ckpt/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras-ckpt/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 184ms/step - loss: 2.3122 - accuracy: 0.0922\n",
            "Epoch 2/3\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.3087 - accuracy: 0.0898INFO:tensorflow:Assets written to: /tmp/keras-ckpt/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras-ckpt/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 144ms/step - loss: 2.3075 - accuracy: 0.0922\n",
            "Epoch 3/3\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.3117 - accuracy: 0.0781WARNING:tensorflow:5 out of the last 9 calls to <function Sequential.call at 0x7f975bdeaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Sequential.call at 0x7f975bdeaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function Sequential.call at 0x7f975bdeaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function Sequential.call at 0x7f975bdeaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras-ckpt/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras-ckpt/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 1s 148ms/step - loss: 2.3113 - accuracy: 0.0750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f978028abe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYyGthHcl6xQ",
        "colab_type": "text"
      },
      "source": [
        "#3. Multi-worker training with Estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swWu2tI4mBgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import os, json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNnEEu55mEu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def input_fn(mode, input_context=None):\n",
        "  datasets, info = tfds.load(name='mnist',\n",
        "                                with_info=True,\n",
        "                                as_supervised=True)\n",
        "  mnist_dataset = (datasets['train'] if mode == tf.estimator.ModeKeys.TRAIN else\n",
        "                   datasets['test'])\n",
        "\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "    return image, label\n",
        "\n",
        "  if input_context:\n",
        "    mnist_dataset = mnist_dataset.shard(input_context.num_input_pipelines,\n",
        "                                        input_context.input_pipeline_id)\n",
        "  return mnist_dataset.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Duerx814mH1n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['TF_CONFIG'] = json.dumps({\n",
        "    'cluster': {\n",
        "        'worker': [\"localhost:12345\", \"localhost:23456\"]\n",
        "    },\n",
        "    'task': {'type': 'worker', 'index': 0}\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q_NOs7WmMPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 1e-4\n",
        "def model_fn(features, labels, mode):\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "  logits = model(features, training=False)\n",
        "\n",
        "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
        "    predictions = {'logits': logits}\n",
        "    return tf.estimator.EstimatorSpec(labels=labels, predictions=predictions)\n",
        "\n",
        "  optimizer = tf.compat.v1.train.GradientDescentOptimizer(\n",
        "      learning_rate=LEARNING_RATE)\n",
        "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True, reduction=tf.keras.losses.Reduction.NONE)(labels, logits)\n",
        "  loss = tf.reduce_sum(loss) * (1. / BATCH_SIZE)\n",
        "  if mode == tf.estimator.ModeKeys.EVAL:\n",
        "    return tf.estimator.EstimatorSpec(mode, loss=loss)\n",
        "\n",
        "  return tf.estimator.EstimatorSpec(\n",
        "      mode=mode,\n",
        "      loss=loss,\n",
        "      train_op=optimizer.minimize(\n",
        "          loss, tf.compat.v1.train.get_or_create_global_step()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q7_KsTZmOgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "1e107841-5c26-4c08-ad1e-536e9968dad8"
      },
      "source": [
        "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/device:GPU:0',)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CollectiveCommunication.AUTO\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CollectiveCommunication.AUTO\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltnt7C4ImQb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "532977f5-c87f-4376-f4f9-1641a62fe7c8"
      },
      "source": [
        "config = tf.estimator.RunConfig(train_distribute=strategy)\n",
        "\n",
        "classifier = tf.estimator.Estimator(\n",
        "    model_fn=model_fn, model_dir='/tmp/multiworker', config=config)\n",
        "tf.estimator.train_and_evaluate(\n",
        "    classifier,\n",
        "    train_spec=tf.estimator.TrainSpec(input_fn=input_fn),\n",
        "    eval_spec=tf.estimator.EvalSpec(input_fn=input_fn)\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Not using Distribute Coordinator.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Not using Distribute Coordinator.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/multiworker', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f976bdc8978>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/multiworker', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x7f976bdc8978>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Not using Distribute Coordinator.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Not using Distribute Coordinator.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:The `input_fn` accepts an `input_context` which will be given by DistributionStrategy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:The `input_fn` accepts an `input_context` which will be given by DistributionStrategy\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function _combine_distributed_scaffold.<locals>.<lambda> at 0x7f976bdb9bf8> and will run it as-is.\n",
            "Cause: could not parse the source code:\n",
            "\n",
            "      lambda scaffold: scaffold.ready_op, args=(grouped_scaffold,))\n",
            "\n",
            "This error may be avoided by creating the lambda in a standalone statement.\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function _combine_distributed_scaffold.<locals>.<lambda> at 0x7f976bdb9bf8> and will run it as-is.\n",
            "Cause: could not parse the source code:\n",
            "\n",
            "      lambda scaffold: scaffold.ready_op, args=(grouped_scaffold,))\n",
            "\n",
            "This error may be avoided by creating the lambda in a standalone statement.\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function _combine_distributed_scaffold.<locals>.<lambda> at 0x7f976bdb9bf8> and will run it as-is.\n",
            "Cause: could not parse the source code:\n",
            "\n",
            "      lambda scaffold: scaffold.ready_op, args=(grouped_scaffold,))\n",
            "\n",
            "This error may be avoided by creating the lambda in a standalone statement.\n",
            "\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/util.py:96: DistributedIteratorV1.initialize (from tensorflow.python.distribute.input_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the iterator's `initializer` property instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/util.py:96: DistributedIteratorV1.initialize (from tensorflow.python.distribute.input_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use the iterator's `initializer` property instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/multiworker/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/multiworker/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.332498, step = 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.332498, step = 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 67.0489\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 67.0489\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3236234, step = 100 (1.505 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3236234, step = 100 (1.505 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 67.2286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 67.2286\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3229594, step = 200 (1.480 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3229594, step = 200 (1.480 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 67.0664\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 67.0664\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3025613, step = 300 (1.496 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3025613, step = 300 (1.496 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 68.0108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 68.0108\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3166897, step = 400 (1.475 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3166897, step = 400 (1.475 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 70.9713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 70.9713\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3039756, step = 500 (1.399 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3039756, step = 500 (1.399 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 67.572\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 67.572\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3097024, step = 600 (1.478 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3097024, step = 600 (1.478 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 68.0319\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 68.0319\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3039095, step = 700 (1.488 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.3039095, step = 700 (1.488 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 77.8481\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 77.8481\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.2957053, step = 800 (1.270 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.2957053, step = 800 (1.270 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 272.974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 272.974\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.2825198, step = 900 (0.363 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 2.2825198, step = 900 (0.363 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 938...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 938...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 938 into /tmp/multiworker/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 938 into /tmp/multiworker/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 938...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 938...\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-04-19T13:21:00Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-04-19T13:21:00Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/multiworker/model.ckpt-938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/multiworker/model.ckpt-938\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [10/100]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [10/100]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [20/100]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [20/100]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [30/100]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [30/100]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [40/100]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [40/100]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [50/100]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [50/100]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [60/100]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [60/100]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [70/100]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [70/100]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [80/100]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [80/100]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [90/100]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [90/100]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [100/100]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Evaluation [100/100]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Inference Time : 2.52453s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Inference Time : 2.52453s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-04-19-13:21:02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-04-19-13:21:02\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 938: global_step = 938, loss = 2.285105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 938: global_step = 938, loss = 2.285105\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 938: /tmp/multiworker/model.ckpt-938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 938: /tmp/multiworker/model.ckpt-938\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 1.1416316.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 1.1416316.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'global_step': 938, 'loss': 2.285105}, [])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtecS9PPmoPT",
        "colab_type": "text"
      },
      "source": [
        "#4. Save and load a model using a distribution strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UliQdbhdmSlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -q tf-nightly\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import tensorflow as tf\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45-7-G9Amz3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b5aebdbb-0c0f-4d49-9c2d-6e27ee8ac790"
      },
      "source": [
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "def get_data():\n",
        "  datasets, ds_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "  mnist_train, mnist_test = datasets['train'], datasets['test']\n",
        "\n",
        "  BUFFER_SIZE = 10000\n",
        "\n",
        "  BATCH_SIZE_PER_REPLICA = 64\n",
        "  BATCH_SIZE = BATCH_SIZE_PER_REPLICA * mirrored_strategy.num_replicas_in_sync\n",
        "\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "\n",
        "    return image, label\n",
        "\n",
        "  train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "  eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\n",
        "\n",
        "  return train_dataset, eval_dataset\n",
        "\n",
        "def get_model():\n",
        "  with mirrored_strategy.scope():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjpzzTbLm5iv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "8a74830d-9cd0-424d-9973-37b23b9e19a2"
      },
      "source": [
        "model = get_model()\n",
        "train_dataset, eval_dataset = get_data()\n",
        "model.fit(train_dataset, epochs=2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 15s 16ms/step - loss: 0.2012 - accuracy: 0.9414\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0664 - accuracy: 0.9808\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f976aa22390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajNZZ6XInArN",
        "colab_type": "text"
      },
      "source": [
        "##4.1. Save and load the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNMvjC2pm7Ik",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "2671f464-826a-423a-8d5a-9912232fcc14"
      },
      "source": [
        "keras_model_path = \"/tmp/keras_save\"\n",
        "model.save(keras_model_path)  # save() should be called out of strategy scope"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function Sequential.call at 0x7f976a937620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function Sequential.call at 0x7f976a937620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 13 calls to <function Sequential.call at 0x7f976a937620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 13 calls to <function Sequential.call at 0x7f976a937620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MxkBU0snE63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4774f2d8-4635-455f-c5d6-8d8a5cf9316c"
      },
      "source": [
        "restored_keras_model = tf.keras.models.load_model(keras_model_path)\n",
        "restored_keras_model.fit(train_dataset, epochs=2)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0485 - accuracy: 0.9855\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0346 - accuracy: 0.9893\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f976a7b65c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO-V8rY8nJ-z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "246d7678-4f60-425b-f57e-a575ebdd3920"
      },
      "source": [
        "another_strategy = tf.distribute.OneDeviceStrategy(\"/cpu:0\")\n",
        "with another_strategy.scope():\n",
        "  restored_keras_model_ds = tf.keras.models.load_model(keras_model_path)\n",
        "  restored_keras_model_ds.fit(train_dataset, epochs=2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "938/938 [==============================] - 32s 34ms/step - loss: 0.0487 - accuracy: 0.9853\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 26s 28ms/step - loss: 0.0338 - accuracy: 0.9896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmYwpjlhnVLp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "c84108df-318e-46cf-fe55-8b85eb5efa3c"
      },
      "source": [
        "model = get_model()  # get a fresh model\n",
        "saved_model_path = \"/tmp/tf_save\"\n",
        "tf.saved_model.save(model, saved_model_path)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function Sequential.call at 0x7f976a55d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function Sequential.call at 0x7f976a55d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 13 calls to <function Sequential.call at 0x7f976a55d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 13 calls to <function Sequential.call at 0x7f976a55d950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function MultiDeviceSaver._traced_save at 0x7f976a4d3d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function MultiDeviceSaver._traced_save at 0x7f976a4d3d90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function MultiDeviceSaver._traced_restore at 0x7f976a44fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function MultiDeviceSaver._traced_restore at 0x7f976a44fd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9SNUVaOngCW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DEFAULT_FUNCTION_KEY = \"serving_default\"\n",
        "loaded = tf.saved_model.load(saved_model_path)\n",
        "inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlHuv752noFI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f871bfd4-aed0-4b75-feab-b666f26dae5a"
      },
      "source": [
        "predict_dataset = eval_dataset.map(lambda image, label: image)\n",
        "for batch in predict_dataset.take(1):\n",
        "  print(inference_func(batch))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'dense_9': <tf.Tensor: shape=(64, 10), dtype=float32, numpy=\n",
            "array([[ 1.20423757e-01, -2.97383256e-02,  9.88389775e-02,\n",
            "        -2.22370643e-02,  1.67440370e-01,  1.92166314e-01,\n",
            "         5.23047820e-02, -2.69944593e-02,  1.27993852e-01,\n",
            "        -1.91377718e-02],\n",
            "       [ 1.50432938e-03, -1.87287070e-02,  1.30669415e-01,\n",
            "        -3.37229036e-02,  1.08764932e-01,  5.96074276e-02,\n",
            "        -8.90557468e-03,  1.54890185e-02, -5.62171899e-02,\n",
            "        -6.23512380e-02],\n",
            "       [ 1.63531348e-01,  1.54542223e-01,  1.11862265e-01,\n",
            "        -5.21031283e-02,  1.80739045e-01,  1.31099030e-01,\n",
            "         2.59890854e-02,  3.37931402e-02,  8.72661099e-02,\n",
            "        -7.46712312e-02],\n",
            "       [-5.71924821e-02,  1.80542737e-01,  1.63176060e-01,\n",
            "        -1.57503277e-01,  2.82266419e-02,  1.41514167e-01,\n",
            "         1.36838123e-01,  4.68262173e-02,  3.30612101e-02,\n",
            "        -1.07180784e-02],\n",
            "       [ 5.77889867e-02, -6.17121235e-02,  1.47768125e-01,\n",
            "        -1.08340293e-01,  1.06360964e-01,  5.73521294e-02,\n",
            "         8.43004286e-02, -9.91749093e-02,  7.01672137e-02,\n",
            "         1.71985216e-02],\n",
            "       [-1.69036277e-02,  1.83045715e-02,  5.27223498e-02,\n",
            "        -8.66687745e-02,  1.85375094e-01,  1.66193351e-01,\n",
            "         1.64871976e-01, -1.16202682e-01,  1.98256582e-01,\n",
            "        -5.09478450e-02],\n",
            "       [ 7.26049915e-02,  5.77473529e-02,  1.06180266e-01,\n",
            "         3.81239876e-02,  1.20325617e-01, -4.79319645e-03,\n",
            "         6.58073416e-03,  2.45315377e-02, -8.91731009e-02,\n",
            "         1.52807450e-02],\n",
            "       [-2.17536371e-02,  1.15003601e-01,  3.49591821e-02,\n",
            "        -8.53026956e-02,  1.71644926e-01,  9.23673362e-02,\n",
            "         8.19174871e-02, -9.91366655e-02,  1.21670388e-01,\n",
            "        -1.12849902e-02],\n",
            "       [ 1.65168829e-02,  1.05285019e-01,  2.95366198e-02,\n",
            "        -1.12646818e-02,  1.96374133e-01,  1.12504356e-01,\n",
            "         4.76178378e-02, -5.21255583e-02,  1.86630879e-02,\n",
            "        -1.53392658e-01],\n",
            "       [-6.16751902e-04,  9.29940119e-02,  9.44792554e-02,\n",
            "         3.83899063e-02,  3.74301970e-02,  1.56645015e-01,\n",
            "         1.09800324e-01, -9.11890715e-02,  2.23129094e-02,\n",
            "        -3.05370819e-02],\n",
            "       [ 1.10628113e-01,  4.30165837e-03,  1.32720158e-01,\n",
            "        -6.92246333e-02,  2.07210436e-01,  1.19544499e-01,\n",
            "         1.20661288e-01, -1.01702675e-01,  4.01718095e-02,\n",
            "        -3.05059552e-02],\n",
            "       [ 3.07804570e-02,  4.64652851e-02,  9.94319469e-02,\n",
            "         4.43522483e-02,  1.99573398e-01,  5.45343570e-02,\n",
            "         9.02329460e-02, -4.04631905e-02,  5.85728176e-02,\n",
            "        -4.87017445e-02],\n",
            "       [ 1.43201426e-01,  9.05164555e-02,  2.91535184e-02,\n",
            "        -4.44267578e-02,  9.97863263e-02,  3.31769064e-02,\n",
            "         1.79341257e-01, -3.54230814e-02,  9.51545909e-02,\n",
            "         3.55994627e-02],\n",
            "       [ 5.17845750e-02,  8.68905857e-02,  1.41613811e-01,\n",
            "        -1.62933290e-01, -9.92489606e-03,  1.29899472e-01,\n",
            "         1.66181564e-01, -1.37965813e-01,  1.20002419e-01,\n",
            "         3.53123881e-02],\n",
            "       [ 5.36900572e-03,  8.89331475e-02,  1.48209676e-01,\n",
            "        -9.53461826e-02,  2.75574531e-02,  1.64014921e-01,\n",
            "         1.42930657e-01,  9.73161776e-03,  7.52240047e-02,\n",
            "        -1.28774568e-02],\n",
            "       [ 1.18900247e-01, -3.86623442e-02,  1.58489108e-01,\n",
            "        -6.89938739e-02,  1.47499591e-01,  1.64596871e-01,\n",
            "         7.00810477e-02, -4.95738536e-02,  1.05804600e-01,\n",
            "        -2.45230626e-02],\n",
            "       [-6.99370448e-03,  1.11694001e-01,  8.20091665e-02,\n",
            "        -1.11265421e-01,  4.54202704e-02,  1.70208558e-01,\n",
            "         2.17953101e-01,  2.91015040e-02, -2.41066646e-02,\n",
            "        -8.22213069e-02],\n",
            "       [ 2.48859692e-02,  9.11841989e-02,  5.55212125e-02,\n",
            "        -6.80094734e-02,  1.92076385e-01,  1.80696160e-01,\n",
            "         1.61959156e-01, -1.65077761e-01,  9.66032445e-02,\n",
            "        -7.94719234e-02],\n",
            "       [ 1.29449248e-01,  8.25339332e-02, -2.80561782e-02,\n",
            "        -2.11270247e-02,  5.35093285e-02,  6.34874552e-02,\n",
            "         1.45462304e-01, -5.14633134e-02, -3.32035646e-02,\n",
            "         1.45093556e-02],\n",
            "       [ 5.09372689e-02,  8.00402090e-02,  1.45430729e-01,\n",
            "        -9.00747478e-02,  1.34557694e-01,  6.76159188e-02,\n",
            "         8.73855501e-02,  8.45393315e-02,  1.03085525e-01,\n",
            "         2.73469537e-02],\n",
            "       [ 6.69152290e-02, -3.84544544e-02,  5.90473004e-02,\n",
            "        -5.54769412e-02,  1.33771405e-01,  1.11239865e-01,\n",
            "         1.27246648e-01, -5.11092804e-02,  5.98726757e-02,\n",
            "        -8.89628753e-02],\n",
            "       [ 2.37486865e-02,  2.22247038e-02,  9.92653444e-02,\n",
            "        -3.15751284e-02,  4.46580350e-02,  1.99773699e-01,\n",
            "         8.38483870e-02, -1.13443278e-01,  8.56012180e-02,\n",
            "         1.99969057e-02],\n",
            "       [ 4.59906674e-04,  7.76431710e-02,  8.76824260e-02,\n",
            "        -7.43272826e-02,  2.27525353e-01,  1.09255075e-01,\n",
            "         6.90148100e-02, -8.15655217e-02, -5.76526858e-03,\n",
            "        -2.05634702e-02],\n",
            "       [ 1.16202738e-02, -4.00134251e-02,  3.27855572e-02,\n",
            "         9.29718558e-03,  1.19795620e-01,  5.91720268e-02,\n",
            "        -5.18347248e-02,  9.19941366e-02, -2.70957388e-02,\n",
            "        -1.17950581e-01],\n",
            "       [-3.62273268e-02,  8.27187076e-02,  1.68729290e-01,\n",
            "         9.21788514e-02,  4.73985858e-02,  2.83086896e-01,\n",
            "         5.78518920e-02, -5.93039244e-02,  2.76752021e-02,\n",
            "        -8.56525376e-02],\n",
            "       [ 8.59007705e-03,  1.63096547e-01,  2.60543842e-02,\n",
            "        -8.77722949e-02,  1.49868533e-01,  1.60129130e-01,\n",
            "         1.36898875e-01, -6.90477788e-02,  4.35148366e-02,\n",
            "        -6.36084303e-02],\n",
            "       [ 2.79540084e-02,  7.90428147e-02,  5.32197803e-02,\n",
            "        -5.33825010e-02,  6.41592517e-02,  1.36380166e-01,\n",
            "         7.18686506e-02, -1.40057415e-01,  7.09867254e-02,\n",
            "        -6.12018332e-02],\n",
            "       [ 1.02199651e-02,  3.34253795e-02,  2.20969878e-02,\n",
            "        -5.04786931e-02,  2.85825759e-01,  1.58599809e-01,\n",
            "         1.84437349e-01, -1.36668012e-01,  2.35095948e-01,\n",
            "        -9.93233994e-02],\n",
            "       [ 1.11831889e-01, -1.02285899e-01,  2.21392155e-01,\n",
            "        -8.33373964e-02,  2.44167805e-01, -2.44404413e-02,\n",
            "         1.03514634e-01, -1.97368503e-01,  1.54353932e-01,\n",
            "         8.68017972e-02],\n",
            "       [ 4.08664718e-02,  6.17865585e-02,  4.72416133e-02,\n",
            "        -2.47881580e-02,  1.31910890e-01,  1.14138424e-01,\n",
            "         1.09345347e-01,  5.58435097e-02,  7.18043596e-02,\n",
            "        -8.89427662e-02],\n",
            "       [ 7.22356737e-02,  5.44753969e-02,  4.97428998e-02,\n",
            "        -5.32699041e-02,  1.10241696e-01,  6.67097121e-02,\n",
            "         8.86608809e-02,  2.33935285e-02,  6.34294301e-02,\n",
            "        -8.01362693e-02],\n",
            "       [ 5.58095351e-02,  1.27075821e-01,  8.24541226e-02,\n",
            "        -9.17248055e-03,  1.55379578e-01,  1.24533497e-01,\n",
            "         8.53194967e-02, -8.56826380e-02,  2.98129432e-02,\n",
            "         3.02314702e-02],\n",
            "       [-3.93659320e-05,  5.17912060e-02,  1.04761280e-01,\n",
            "         2.66084913e-02,  1.36803821e-01,  1.33818150e-01,\n",
            "         4.20715250e-02, -1.50232673e-01,  2.68310811e-02,\n",
            "        -8.00310075e-02],\n",
            "       [ 1.26055822e-01, -3.85164544e-02,  3.86157399e-03,\n",
            "        -4.32423167e-02,  1.10031776e-01,  3.17189805e-02,\n",
            "         3.03796418e-02, -1.88449696e-01,  5.12543134e-02,\n",
            "         5.61253503e-02],\n",
            "       [-4.24708705e-03, -9.62873176e-03,  3.80497500e-02,\n",
            "         2.11704187e-02,  9.47302952e-02,  5.55287376e-02,\n",
            "        -3.06166708e-02, -8.91590714e-02, -2.76892614e-02,\n",
            "        -6.47158548e-02],\n",
            "       [ 1.09641589e-01, -3.10050026e-02,  1.68623224e-01,\n",
            "        -1.17886946e-01,  1.68112427e-01,  6.69747740e-02,\n",
            "         1.44524261e-01, -2.30167564e-02,  1.05433613e-01,\n",
            "        -1.13822497e-01],\n",
            "       [ 8.69617015e-02,  1.17043540e-01,  1.76772356e-01,\n",
            "        -5.91638358e-03,  1.04306258e-01,  2.51275450e-01,\n",
            "         1.74310148e-01, -5.53400582e-03,  4.43579704e-02,\n",
            "        -4.10871208e-02],\n",
            "       [-3.22523229e-02,  1.37000307e-01,  2.04931885e-01,\n",
            "        -1.02534719e-01,  6.55081645e-02,  2.49105558e-01,\n",
            "         1.96568534e-01, -6.84258947e-03, -4.36852090e-02,\n",
            "         4.16237861e-02],\n",
            "       [ 7.84027725e-02,  1.18518800e-01,  1.04433335e-02,\n",
            "        -9.34122354e-02,  5.66934533e-02,  7.35649541e-02,\n",
            "         1.50522456e-01,  2.37338655e-02,  4.34812680e-02,\n",
            "        -1.21348605e-01],\n",
            "       [-2.76927557e-03,  1.49877280e-01,  1.33725464e-01,\n",
            "        -1.46118268e-01,  1.25542909e-01,  2.32273445e-01,\n",
            "         1.36880755e-01,  1.94269549e-02, -9.40449070e-03,\n",
            "         1.83173046e-02],\n",
            "       [ 5.29870987e-02, -4.58979094e-03,  1.32792741e-02,\n",
            "        -3.73672433e-02,  1.70686841e-01,  1.54404482e-02,\n",
            "         3.47344540e-02, -5.53406440e-02,  1.67513452e-02,\n",
            "        -1.04519706e-02],\n",
            "       [ 1.02611654e-01,  7.26288185e-02,  1.21086054e-01,\n",
            "        -1.06524915e-01,  1.49015397e-01,  1.76500335e-01,\n",
            "         1.32255554e-01, -7.12781623e-02,  1.48361415e-01,\n",
            "        -6.01853384e-03],\n",
            "       [ 8.87987092e-02,  4.33674753e-02,  2.46774666e-02,\n",
            "        -3.23372446e-02,  1.37700588e-01,  1.25495240e-01,\n",
            "         8.12950283e-02, -1.04507729e-01,  1.20288156e-01,\n",
            "        -3.96202691e-02],\n",
            "       [ 1.46232713e-02,  8.80762786e-02,  1.29731059e-01,\n",
            "         5.38572930e-02,  7.19352588e-02,  1.73094094e-01,\n",
            "         9.87759158e-02, -1.30090667e-02,  1.12662911e-01,\n",
            "         5.24630351e-03],\n",
            "       [ 8.74692947e-02, -9.76407155e-02,  1.71165869e-01,\n",
            "        -1.13938659e-01,  6.54723644e-02,  1.09423131e-01,\n",
            "         9.84451324e-02, -7.26830512e-02,  7.23178536e-02,\n",
            "        -3.25043835e-02],\n",
            "       [ 8.36413205e-02,  1.34829074e-01,  1.79408431e-01,\n",
            "         4.93280329e-02,  8.66760612e-02,  3.29257339e-01,\n",
            "         1.95544362e-01, -1.74784884e-02,  1.46213137e-02,\n",
            "        -6.67817472e-03],\n",
            "       [ 1.09821893e-01,  9.52926651e-02,  5.22539914e-02,\n",
            "        -8.16980600e-02,  5.27166352e-02,  8.03391486e-02,\n",
            "         1.58469185e-01, -5.26884645e-02,  5.09727597e-02,\n",
            "        -1.81178853e-03],\n",
            "       [ 8.38690698e-02, -2.44781151e-02,  1.23943686e-01,\n",
            "         6.39037117e-02,  1.62234202e-01,  1.16421111e-01,\n",
            "         2.58012619e-02, -7.97548369e-02,  8.77631232e-02,\n",
            "         5.85449189e-02],\n",
            "       [ 3.69616970e-02,  1.49758473e-01,  1.43348023e-01,\n",
            "        -1.30541593e-01,  5.93334483e-03,  6.21085837e-02,\n",
            "         6.37046620e-02,  7.23571330e-02,  3.75437248e-03,\n",
            "         2.89984643e-02],\n",
            "       [-4.11681123e-02,  8.66210982e-02,  1.26979619e-01,\n",
            "         2.89173913e-03, -6.03056862e-04,  1.72450423e-01,\n",
            "         9.50919166e-02, -6.01330325e-02,  2.97467392e-02,\n",
            "        -1.49597758e-02],\n",
            "       [-2.13293708e-03, -2.25567874e-02,  4.09344211e-02,\n",
            "         4.87412363e-02,  1.24745294e-01,  7.23368526e-02,\n",
            "         3.02454736e-02,  3.02174948e-02,  2.79774163e-02,\n",
            "        -7.65364617e-02],\n",
            "       [ 1.01108223e-01,  7.59244412e-02,  2.91417576e-02,\n",
            "        -1.11129515e-01, -1.43635413e-02,  7.65208602e-02,\n",
            "         1.70583740e-01, -2.29272153e-02,  2.51131169e-02,\n",
            "         2.73755882e-02],\n",
            "       [ 7.65686631e-02,  4.16364633e-02, -2.85130050e-02,\n",
            "        -4.79083247e-02,  4.63681258e-02,  5.36675416e-02,\n",
            "         9.82031599e-02, -4.02065180e-02,  6.51649460e-02,\n",
            "        -1.70323178e-02],\n",
            "       [ 1.37609154e-01, -6.06489331e-02,  4.22843285e-02,\n",
            "        -1.78386807e-01,  1.66271478e-01, -6.83329329e-02,\n",
            "         1.39033675e-01, -3.28862667e-02,  2.15937033e-01,\n",
            "        -9.01034102e-02],\n",
            "       [ 1.26342386e-01,  8.21195170e-02,  4.36422564e-02,\n",
            "        -2.00835407e-01,  8.71610418e-02, -1.02256995e-03,\n",
            "         1.44086897e-01,  2.39602514e-02,  2.08036467e-01,\n",
            "        -1.01527192e-01],\n",
            "       [ 1.06442720e-01, -2.70208325e-02,  5.84839992e-02,\n",
            "        -4.87361774e-02,  1.60510644e-01,  1.53817222e-01,\n",
            "         9.91586670e-02, -1.19698942e-01,  2.24449620e-01,\n",
            "        -6.90192282e-02],\n",
            "       [ 3.31738293e-02,  1.11725986e-01,  1.05834424e-01,\n",
            "        -3.87620268e-04,  1.59758516e-02,  3.75134498e-02,\n",
            "         3.97048555e-02, -4.67166081e-02, -4.43429053e-02,\n",
            "         2.68613193e-02],\n",
            "       [ 9.00121704e-02,  1.51138425e-01,  8.88748839e-02,\n",
            "        -1.31341308e-01,  1.18595496e-01,  1.14560552e-01,\n",
            "         1.71890035e-01, -1.25430658e-01,  8.41777548e-02,\n",
            "        -1.67115685e-02],\n",
            "       [ 3.27946134e-02,  3.99413193e-03,  1.59541428e-01,\n",
            "        -4.74057393e-03,  9.86729637e-02,  1.09942317e-01,\n",
            "         1.80205107e-01,  2.18278132e-02,  7.85808340e-02,\n",
            "        -1.89102851e-02],\n",
            "       [ 1.27047688e-01, -1.29160970e-01,  1.15666784e-01,\n",
            "        -2.32092990e-03,  1.83275789e-01,  8.84309858e-02,\n",
            "         6.90481365e-02, -1.83908448e-01,  1.58116028e-01,\n",
            "        -7.29010478e-02],\n",
            "       [ 1.94866955e-01, -4.62559909e-02,  1.02143930e-02,\n",
            "         2.63775010e-02,  1.20547302e-01,  3.10720485e-02,\n",
            "         4.37837355e-02, -9.48975384e-02,  7.75816590e-02,\n",
            "         1.12440623e-02],\n",
            "       [ 1.14011504e-01,  1.75195746e-02,  7.56214112e-02,\n",
            "        -4.36153337e-02,  1.63005203e-01,  6.58426359e-02,\n",
            "         1.13110028e-01, -2.46031233e-03,  1.85282603e-01,\n",
            "        -6.04793243e-02],\n",
            "       [-1.13658294e-01,  8.34598094e-02,  2.06576183e-01,\n",
            "        -4.54836674e-02,  2.51971348e-03,  1.80792466e-01,\n",
            "         1.25401214e-01,  8.32095519e-02, -1.02647983e-01,\n",
            "         1.02908341e-02],\n",
            "       [ 1.80226043e-01,  1.44837927e-02, -6.45480454e-02,\n",
            "        -1.39730321e-02,  7.19361305e-02,  7.97405094e-02,\n",
            "         1.90442372e-02, -4.30962965e-02,  1.07560329e-01,\n",
            "         4.42089662e-02]], dtype=float32)>}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FpS8kWNnrCw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "13bec99a-464c-4975-8fc0-c97a31869af1"
      },
      "source": [
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "with another_strategy.scope():\n",
        "  loaded = tf.saved_model.load(saved_model_path)\n",
        "  inference_func = loaded.signatures[DEFAULT_FUNCTION_KEY]\n",
        "\n",
        "  dist_predict_dataset = another_strategy.experimental_distribute_dataset(\n",
        "      predict_dataset)\n",
        "\n",
        "  # Calling the function in a distributed manner\n",
        "  for batch in dist_predict_dataset:\n",
        "    another_strategy.run(inference_func,args=(batch,))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `experimental_run_v2` inside a tf.function to get the best performance.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpgp--ZGntkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "971057fa-f269-4933-dcdc-9a71616d3f90"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "def build_model(loaded):\n",
        "  x = tf.keras.layers.Input(shape=(28, 28, 1), name='input_x')\n",
        "  # Wrap what's loaded to a KerasLayer\n",
        "  keras_layer = hub.KerasLayer(loaded, trainable=True)(x)\n",
        "  model = tf.keras.Model(x, keras_layer)\n",
        "  return model\n",
        "\n",
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "with another_strategy.scope():\n",
        "  loaded = tf.saved_model.load(saved_model_path)\n",
        "  model = build_model(loaded)\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "  model.fit(train_dataset, epochs=2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "938/938 [==============================] - 15s 15ms/step - loss: 0.1993 - accuracy: 0.9419\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.0683 - accuracy: 0.9798\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNqDTuNOnwGX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "c3f528dc-5024-4f33-a349-1a3d73554848"
      },
      "source": [
        "model = get_model()\n",
        "\n",
        "# Saving the model using Keras's save() API\n",
        "model.save(keras_model_path) \n",
        "\n",
        "another_strategy = tf.distribute.MirroredStrategy()\n",
        "# Loading the model using lower level API\n",
        "with another_strategy.scope():\n",
        "  loaded = tf.saved_model.load(keras_model_path)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function Sequential.call at 0x7f976a2ce8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function Sequential.call at 0x7f976a2ce8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 13 calls to <function Sequential.call at 0x7f976a2ce8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 13 calls to <function Sequential.call at 0x7f976a2ce8c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function MultiDeviceSaver._traced_save at 0x7f976a260f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function MultiDeviceSaver._traced_save at 0x7f976a260f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function MultiDeviceSaver._traced_restore at 0x7f976a179d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function MultiDeviceSaver._traced_restore at 0x7f976a179d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras_save/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFbzXcDBnzLI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "8a3bb534-edde-4a7c-898e-65da3d8c7514"
      },
      "source": [
        "class SubclassedModel(tf.keras.Model):\n",
        "\n",
        "  output_name = 'output_layer'\n",
        "\n",
        "  def __init__(self):\n",
        "    super(SubclassedModel, self).__init__()\n",
        "    self._dense_layer = tf.keras.layers.Dense(\n",
        "        5, dtype=tf.dtypes.float32, name=self.output_name)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return self._dense_layer(inputs)\n",
        "\n",
        "my_model = SubclassedModel()\n",
        "# my_model.save(keras_model_path)  # ERROR! \n",
        "tf.saved_model.save(my_model, saved_model_path)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.SubclassedModel object at 0x7f976a175908>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.SubclassedModel object at 0x7f976a175908>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f976a175fd0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dense object at 0x7f976a175fd0>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function MultiDeviceSaver._traced_save at 0x7f976a2ce1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function MultiDeviceSaver._traced_save at 0x7f976a2ce1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function MultiDeviceSaver._traced_restore at 0x7f976a2ce950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:7 out of the last 7 calls to <function MultiDeviceSaver._traced_restore at 0x7f976a2ce950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tf_save/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smx_uCvjoAas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}