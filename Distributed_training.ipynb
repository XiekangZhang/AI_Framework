{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Distributed_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FohCev-137Wv",
        "colab_type": "text"
      },
      "source": [
        "#1. Distributed training with Keras\n",
        "\n",
        "API provides an abstraction for distributing your training across multiple processing units. The goal is to allow users to enable distributed training using existing models and training code, with minimal changes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPExf5--3jnS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f322db3f-c33d-4912-997f-71a31d2a4502"
      },
      "source": [
        "!pip install -q tf-nightly\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 519.0MB 31kB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 39.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 39.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oPjiFiJ5eDv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7a49cf9-cd37-4efd-c7fb-8d3161eab652"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-dev20200419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2wxTkDA5zFk",
        "colab_type": "text"
      },
      "source": [
        "##1.1. Download the dataset\n",
        "\n",
        "Setting with_info to True includes the medadata for the entiredataset, which is being saved here to info. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5UFKr045h4p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "5088c699-d675-4b9b-8957-d58934e51983"
      },
      "source": [
        "datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
        "mnist_train, mnist_test = datasets['train'], datasets['test']"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to /root/tensorflow_datasets/mnist/3.0.0...\u001b[0m\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um_k-u_W6UKT",
        "colab_type": "text"
      },
      "source": [
        "##1.2. Define distribution strategy\n",
        "\n",
        "Create a MirroredStrategy object. This will handle distribution, and provides a context manager to build your model inside."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgNHIGYH6RNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "997e9356-9b6f-4bfe-83c7-3cda7663de0c"
      },
      "source": [
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8lpI7Nr6t7b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2694b553-1ffa-4c1e-d1de-0cc3af675163"
      },
      "source": [
        "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWV38yMI624y",
        "colab_type": "text"
      },
      "source": [
        "##1.3. Setup input pipeline\n",
        "\n",
        "When training a model with multiple GPUs, you can use the extra computing power effectively by increasing the batch size. In general, use the largest batch size that fits the GPU memory, and tune the learning rate accordingly. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kure8Rbi60A4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You can also do info.splits.total_num_examples to get the total\n",
        "# number of examples in the dataset.\n",
        "\n",
        "num_train_examples = info.splits['train'].num_examples\n",
        "num_test_examples = info.splits['test'].num_examples\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8wq6gvB75OM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pixel values, which are 0-255, have to be normalized to the 0-1 range\n",
        "def scale(image, label):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  image /= 255\n",
        "  \n",
        "  return image, label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esugZLUr85T4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Apply this function to the training and test data. \n",
        "# shuffle the training data, and batch it for training. \n",
        "# Notice we are alos keeping an in-memory cache of the training data to improve performance.\n",
        "\n",
        "train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgWmRw1m9x03",
        "colab_type": "text"
      },
      "source": [
        "##1.4. Create the model\n",
        "\n",
        "Create and compile the Keras model in the context of strategy.scope"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS4jIY2n9wby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TThViyee-B-d",
        "colab_type": "text"
      },
      "source": [
        "##1.5. Define the callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvei3pSJ-Aat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the checkpoint directory to store the checkpoints\n",
        "\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5x8_Py-H-L87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function for decaying the learning rate.\n",
        "# You can define any decay function you need.\n",
        "def decay(epoch):\n",
        "  if epoch < 3:\n",
        "    return 1e-3\n",
        "  elif epoch >= 3 and epoch < 7:\n",
        "    return 1e-4\n",
        "  else:\n",
        "    return 1e-5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmou36KD-S0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Callback for printing the LR at the end of each epoch.\n",
        "class PrintLR(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
        "                                                      model.optimizer.lr.numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "co3Uwq_x-kX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks = [\n",
        "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
        "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n",
        "                                       save_weights_only=True),\n",
        "    tf.keras.callbacks.LearningRateScheduler(decay),\n",
        "    PrintLR()\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMuHqjcT-qnT",
        "colab_type": "text"
      },
      "source": [
        "##1.6. Train and evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhdHNSZa-oe0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "cf49670a-4129-4246-d78a-48b9aa18cb8d"
      },
      "source": [
        "model.fit(train_dataset, epochs=12, callbacks=callbacks)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "  1/938 [..............................] - ETA: 0s - loss: 2.2961 - accuracy: 0.1875WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1271: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1271: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "937/938 [============================>.] - ETA: 0s - loss: 0.2095 - accuracy: 0.9388\n",
            "Learning rate for epoch 1 is 0.0010000000474974513\n",
            "938/938 [==============================] - 31s 33ms/step - loss: 0.2093 - accuracy: 0.9388\n",
            "Epoch 2/12\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0658 - accuracy: 0.9806\n",
            "Learning rate for epoch 2 is 0.0010000000474974513\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0658 - accuracy: 0.9806\n",
            "Epoch 3/12\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0460 - accuracy: 0.9862\n",
            "Learning rate for epoch 3 is 0.0010000000474974513\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0460 - accuracy: 0.9862\n",
            "Epoch 4/12\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0251 - accuracy: 0.9929\n",
            "Learning rate for epoch 4 is 9.999999747378752e-05\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0251 - accuracy: 0.9929\n",
            "Epoch 5/12\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0219 - accuracy: 0.9940\n",
            "Learning rate for epoch 5 is 9.999999747378752e-05\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0219 - accuracy: 0.9940\n",
            "Epoch 6/12\n",
            "938/938 [==============================] - ETA: 0s - loss: 0.0200 - accuracy: 0.9947\n",
            "Learning rate for epoch 6 is 9.999999747378752e-05\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0200 - accuracy: 0.9947\n",
            "Epoch 7/12\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0185 - accuracy: 0.9953\n",
            "Learning rate for epoch 7 is 9.999999747378752e-05\n",
            "938/938 [==============================] - 27s 29ms/step - loss: 0.0185 - accuracy: 0.9953\n",
            "Epoch 8/12\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0160 - accuracy: 0.9963\n",
            "Learning rate for epoch 8 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 0.0160 - accuracy: 0.9963\n",
            "Epoch 9/12\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9964\n",
            "Learning rate for epoch 9 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0157 - accuracy: 0.9964\n",
            "Epoch 10/12\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0156 - accuracy: 0.9964\n",
            "Learning rate for epoch 10 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 26s 27ms/step - loss: 0.0155 - accuracy: 0.9964\n",
            "Epoch 11/12\n",
            "936/938 [============================>.] - ETA: 0s - loss: 0.0154 - accuracy: 0.9965\n",
            "Learning rate for epoch 11 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0154 - accuracy: 0.9965\n",
            "Epoch 12/12\n",
            "937/938 [============================>.] - ETA: 0s - loss: 0.0152 - accuracy: 0.9964\n",
            "Learning rate for epoch 12 is 9.999999747378752e-06\n",
            "938/938 [==============================] - 25s 27ms/step - loss: 0.0152 - accuracy: 0.9964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcfaa33b9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XayGnOhA-wgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "495a7b8c-bc3f-4999-bcc3-7647b62533dd"
      },
      "source": [
        "# check the checkpoint directory\n",
        "!ls {checkpoint_dir}"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\t\t     ckpt_4.data-00000-of-00001\n",
            "ckpt_10.data-00000-of-00001  ckpt_4.index\n",
            "ckpt_10.index\t\t     ckpt_5.data-00000-of-00001\n",
            "ckpt_11.data-00000-of-00001  ckpt_5.index\n",
            "ckpt_11.index\t\t     ckpt_6.data-00000-of-00001\n",
            "ckpt_12.data-00000-of-00001  ckpt_6.index\n",
            "ckpt_12.index\t\t     ckpt_7.data-00000-of-00001\n",
            "ckpt_1.data-00000-of-00001   ckpt_7.index\n",
            "ckpt_1.index\t\t     ckpt_8.data-00000-of-00001\n",
            "ckpt_2.data-00000-of-00001   ckpt_8.index\n",
            "ckpt_2.index\t\t     ckpt_9.data-00000-of-00001\n",
            "ckpt_3.data-00000-of-00001   ckpt_9.index\n",
            "ckpt_3.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9649cb___J34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "39fba44d-63d3-4d6f-b646-4150a1528cde"
      },
      "source": [
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "eval_loss, eval_acc = model.evaluate(eval_dataset)\n",
        "\n",
        "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 3s 22ms/step - loss: 0.0358 - accuracy: 0.9882\n",
            "Eval loss: 0.03579382598400116, Eval Accuracy: 0.9882000088691711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPilpRDM_QWi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "cf3fdf39-2a4b-4bfd-e01e-7f2aea030c28"
      },
      "source": [
        "!tensorboard --logdir=/content/logs"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
            "    sys.exit(run_main())\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/main.py\", line 75, in run_main\n",
            "    app.run(tensorboard.main, flags_parser=tensorboard.configure)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 289, in main\n",
            "    return runner(self.flags) or 0\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 305, in _run_serve_subcommand\n",
            "    server = self._make_server()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/program.py\", line 409, in _make_server\n",
            "    self.flags, self.plugin_loaders, self.assets_zip_provider\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 183, in standard_tensorboard_wsgi\n",
            "    flags, plugin_loaders, data_provider, assets_zip_provider, multiplexer\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 272, in TensorBoardWSGIApp\n",
            "    tbplugins, flags.path_prefix, data_provider, experimental_plugins\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/backend/application.py\", line 345, in __init__\n",
            "    \"Duplicate plugins for name %s\" % plugin.plugin_name\n",
            "ValueError: Duplicate plugins for name projector\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2x604FjTWHT2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3f151fd2-80b9-44b8-b820-3e97bf516537"
      },
      "source": [
        "ls -sh ./logs"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4.0K\n",
            "4.0K \u001b[0m\u001b[01;34mtrain\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lh6EBRQZWnv5",
        "colab_type": "text"
      },
      "source": [
        "##1.7. Export to SavedModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d9dCFhoWlkd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "59655489-9c58-46f6-e105-05ac1da9a547"
      },
      "source": [
        "path = 'saved_model/'\n",
        "model.save(path, save_format='tf')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGRoHXcxWzBo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "99c5588b-5ae1-439b-c4bd-3d8e7706bfbf"
      },
      "source": [
        "# Load model without strategy.scope\n",
        "unreplicated_model = tf.keras.models.load_model(path)\n",
        "\n",
        "unreplicated_model.compile(\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    metrics=['accuracy'])\n",
        "\n",
        "eval_loss, eval_acc = unreplicated_model.evaluate(eval_dataset)\n",
        "\n",
        "print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 3s 22ms/step - loss: 0.0358 - accuracy: 0.9882\n",
            "Eval loss: 0.03579382598400116, Eval Accuracy: 0.9882000088691711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sc43XHqpW8wh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7dc725c7-9773-423a-a9bb-6729a5b29506"
      },
      "source": [
        "# Load with strategy.scope\n",
        "with strategy.scope():\n",
        "  replicated_model = tf.keras.models.load_model(path)\n",
        "  replicated_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                           optimizer=tf.keras.optimizers.Adam(),\n",
        "                           metrics=['accuracy'])\n",
        "\n",
        "  eval_loss, eval_acc = replicated_model.evaluate(eval_dataset)\n",
        "  print ('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 3s 22ms/step - loss: 0.0358 - accuracy: 0.9882\n",
            "Eval loss: 0.03579382598400116, Eval Accuracy: 0.9882000088691711\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MH6O-pZ1Xe34",
        "colab_type": "text"
      },
      "source": [
        "#2. Custom training with tf.distribute.Strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-1PdMK4XCRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cdb45d75-2492-42e3-b9d3-0a3f1dcb39bb"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "# Import TensorFlow\n",
        "!pip install -q tf-nightly\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-dev20200419\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfGubpLfYCI-",
        "colab_type": "text"
      },
      "source": [
        "##2.1. Download the fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBRC_l-bX-ql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "e33bf07b-5c48-4aa6-9cd9-378bc6fd80c3"
      },
      "source": [
        "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# Adding a dimension to the array -> new shape == (28, 28, 1)\n",
        "# We are doing this because the first layer in our model is a convolutional\n",
        "# layer and it requires a 4D input (batch_size, height, width, channels).\n",
        "# batch_size dimension will be added later on.\n",
        "train_images = train_images[..., None]\n",
        "test_images = test_images[..., None]\n",
        "\n",
        "# Getting the images in [0, 1] range.\n",
        "train_images = train_images / np.float32(255)\n",
        "test_images = test_images / np.float32(255)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqZRpDpmYkf9",
        "colab_type": "text"
      },
      "source": [
        "##2.2. Create a strategy to distribute the variables and the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DImidhPYiYw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "414ae84f-9f1d-4560-b658-3ce009c28744"
      },
      "source": [
        "# If the list of devices is not specified in the\n",
        "# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cx3fusZRYxh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06cf6e8f-30f4-4684-dfa2-c73c2b436560"
      },
      "source": [
        "print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOB801UFY4Ac",
        "colab_type": "text"
      },
      "source": [
        "##2.3. Setup input pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-hyJFNSY1ub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(train_images)\n",
        "\n",
        "BATCH_SIZE_PER_REPLICA = 64\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "\n",
        "EPOCHS = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA8k2_vOZln2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE) \n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE) \n",
        "\n",
        "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "test_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1PUBZYeZ596",
        "colab_type": "text"
      },
      "source": [
        "##2.4. Create the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnfWVy7gZ5Al",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPXXbZ90aBmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a checkpoint directory to store the checkpoints.\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykHHGBZ_aGl6",
        "colab_type": "text"
      },
      "source": [
        "##2.5. Define the loss function\n",
        "\n",
        "Normally, on a single machine with 1 GPU/CPU, loss is divided by the number of examples in the batch of input. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrQjjoBgaDZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "  # Set reduction to `none` so we can do the reduction afterwards and divide by\n",
        "  # global batch size.\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "      from_logits=True,\n",
        "      reduction=tf.keras.losses.Reduction.NONE)\n",
        "  def compute_loss(labels, predictions):\n",
        "    per_example_loss = loss_object(labels, predictions)\n",
        "    return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvSL2QNPbq0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the metrics to track loss and accuracy\n",
        "with strategy.scope():\n",
        "  test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "\n",
        "  train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='train_accuracy')\n",
        "  test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='test_accuracy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0isTo-Brb16t",
        "colab_type": "text"
      },
      "source": [
        "##2.6. Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51eK3fUDb0LK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model, optimizer, and checkpoint must be created under `strategy.scope`.\n",
        "with strategy.scope():\n",
        "  model = create_model()\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHiAveiTcKFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(inputs):\n",
        "  images, labels = inputs\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    predictions = model(images, training=True)\n",
        "    loss = compute_loss(labels, predictions)\n",
        "\n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "  train_accuracy.update_state(labels, predictions)\n",
        "  return loss \n",
        "\n",
        "def test_step(inputs):\n",
        "  images, labels = inputs\n",
        "\n",
        "  predictions = model(images, training=False)\n",
        "  t_loss = loss_object(labels, predictions)\n",
        "\n",
        "  test_loss.update_state(t_loss)\n",
        "  test_accuracy.update_state(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq1oZXAicMZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "be93ecb9-7bd4-42a5-e6a2-f751e7903cb1"
      },
      "source": [
        "# `run` replicates the provided computation and runs it\n",
        "# with the distributed input.\n",
        "@tf.function\n",
        "def distributed_train_step(dataset_inputs):\n",
        "  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n",
        "  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n",
        "                         axis=None)\n",
        "\n",
        "@tf.function\n",
        "def distributed_test_step(dataset_inputs):\n",
        "  return strategy.run(test_step, args=(dataset_inputs,))\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  # TRAIN LOOP\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "  for x in train_dist_dataset:\n",
        "    total_loss += distributed_train_step(x)\n",
        "    num_batches += 1\n",
        "  train_loss = total_loss / num_batches\n",
        "\n",
        "  # TEST LOOP\n",
        "  for x in test_dist_dataset:\n",
        "    distributed_test_step(x)\n",
        "\n",
        "  if epoch % 2 == 0:\n",
        "    checkpoint.save(checkpoint_prefix)\n",
        "\n",
        "  template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \"\n",
        "              \"Test Accuracy: {}\")\n",
        "  print (template.format(epoch+1, train_loss,\n",
        "                         train_accuracy.result()*100, test_loss.result(),\n",
        "                         test_accuracy.result()*100))\n",
        "\n",
        "  test_loss.reset_states()\n",
        "  train_accuracy.reset_states()\n",
        "  test_accuracy.reset_states()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.5153678059577942, Accuracy: 81.36333465576172, Test Loss: 0.38318201899528503, Test Accuracy: 86.45999908447266\n",
            "Epoch 2, Loss: 0.3339560031890869, Accuracy: 87.94999694824219, Test Loss: 0.32745468616485596, Test Accuracy: 88.47000122070312\n",
            "Epoch 3, Loss: 0.289735347032547, Accuracy: 89.40666961669922, Test Loss: 0.3177132308483124, Test Accuracy: 88.6300048828125\n",
            "Epoch 4, Loss: 0.2589462101459503, Accuracy: 90.55332946777344, Test Loss: 0.3060314953327179, Test Accuracy: 88.80000305175781\n",
            "Epoch 5, Loss: 0.23737187683582306, Accuracy: 91.28500366210938, Test Loss: 0.2779774069786072, Test Accuracy: 89.69000244140625\n",
            "Epoch 6, Loss: 0.21620415151119232, Accuracy: 92.05166625976562, Test Loss: 0.3102119565010071, Test Accuracy: 89.11000061035156\n",
            "Epoch 7, Loss: 0.20048733055591583, Accuracy: 92.55333709716797, Test Loss: 0.25279226899147034, Test Accuracy: 91.18000030517578\n",
            "Epoch 8, Loss: 0.18413300812244415, Accuracy: 93.17666625976562, Test Loss: 0.256083607673645, Test Accuracy: 90.83000183105469\n",
            "Epoch 9, Loss: 0.17164701223373413, Accuracy: 93.57666015625, Test Loss: 0.24966789782047272, Test Accuracy: 91.37999725341797\n",
            "Epoch 10, Loss: 0.15677373111248016, Accuracy: 94.21499633789062, Test Loss: 0.2547090947628021, Test Accuracy: 91.22000122070312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETkQ4cFqdP2k",
        "colab_type": "text"
      },
      "source": [
        "##2.7. Restore the latest checkpoint and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhoEIum-cPlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "      name='eval_accuracy')\n",
        "\n",
        "new_model = create_model()\n",
        "new_optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SBncXWjdTNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def eval_step(images, labels):\n",
        "  predictions = new_model(images, training=False)\n",
        "  eval_accuracy(labels, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPx_HlT4da2e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "987b6af8-459a-4790-ba36-75905574afa1"
      },
      "source": [
        "checkpoint = tf.train.Checkpoint(optimizer=new_optimizer, model=new_model)\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "for images, labels in test_dataset:\n",
        "  eval_step(images, labels)\n",
        "\n",
        "print ('Accuracy after restoring the saved model without strategy: {}'.format(\n",
        "    eval_accuracy.result()*100))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy after restoring the saved model without strategy: 91.37999725341797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9BhUOk6dnew",
        "colab_type": "text"
      },
      "source": [
        "##2.8. Alternate ways of iterating over a dataset\n",
        "\n",
        "If you want to iterate over a given number of steps and not through the entire dataset you can create an iterator using the iter call and explicity call next on the iterator. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAUaVunkdi5j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7e10554f-96f6-445b-a948-f1f3a18b8fec"
      },
      "source": [
        "# Iterating outside a tf.function\n",
        "for _ in range(EPOCHS):\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "  train_iter = iter(train_dist_dataset)\n",
        "\n",
        "  for _ in range(10):\n",
        "    total_loss += distributed_train_step(next(train_iter))\n",
        "    num_batches += 1\n",
        "  average_train_loss = total_loss / num_batches\n",
        "\n",
        "  template = (\"Epoch {}, Loss: {}, Accuracy: {}\")\n",
        "  print (template.format(epoch+1, average_train_loss, train_accuracy.result()*100))\n",
        "  train_accuracy.reset_states()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10, Loss: 0.16225148737430573, Accuracy: 94.21875\n",
            "Epoch 10, Loss: 0.165340855717659, Accuracy: 93.59375\n",
            "Epoch 10, Loss: 0.12995003163814545, Accuracy: 94.6875\n",
            "Epoch 10, Loss: 0.16367259621620178, Accuracy: 94.375\n",
            "Epoch 10, Loss: 0.13290463387966156, Accuracy: 95.78125\n",
            "Epoch 10, Loss: 0.12039406597614288, Accuracy: 95.78125\n",
            "Epoch 10, Loss: 0.1760627180337906, Accuracy: 93.75\n",
            "Epoch 10, Loss: 0.12315411865711212, Accuracy: 94.6875\n",
            "Epoch 10, Loss: 0.14033515751361847, Accuracy: 94.0625\n",
            "Epoch 10, Loss: 0.16444949805736542, Accuracy: 95.15625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH6uK0K2eGJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "2076acc3-13f2-40ce-ea70-ec5fb13c7725"
      },
      "source": [
        "# Iterating inside a tf.function\n",
        "@tf.function\n",
        "def distributed_train_epoch(dataset):\n",
        "  total_loss = 0.0\n",
        "  num_batches = 0\n",
        "  for x in dataset:\n",
        "    per_replica_losses = strategy.run(train_step, args=(x,))\n",
        "    total_loss += strategy.reduce(\n",
        "      tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n",
        "    num_batches += 1\n",
        "  return total_loss / tf.cast(num_batches, dtype=tf.float32)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  train_loss = distributed_train_epoch(train_dist_dataset)\n",
        "\n",
        "  template = (\"Epoch {}, Loss: {}, Accuracy: {}\")\n",
        "  print (template.format(epoch+1, train_loss, train_accuracy.result()*100))\n",
        "\n",
        "  train_accuracy.reset_states()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.1442921906709671, Accuracy: 94.59833526611328\n",
            "Epoch 2, Loss: 0.1308281272649765, Accuracy: 95.17499542236328\n",
            "Epoch 3, Loss: 0.12104317545890808, Accuracy: 95.57833099365234\n",
            "Epoch 4, Loss: 0.1106492206454277, Accuracy: 95.9800033569336\n",
            "Epoch 5, Loss: 0.10212011635303497, Accuracy: 96.17833709716797\n",
            "Epoch 6, Loss: 0.09471506625413895, Accuracy: 96.47666931152344\n",
            "Epoch 7, Loss: 0.0839567556977272, Accuracy: 96.86166381835938\n",
            "Epoch 8, Loss: 0.07851479202508926, Accuracy: 97.16999816894531\n",
            "Epoch 9, Loss: 0.07310765981674194, Accuracy: 97.29166412353516\n",
            "Epoch 10, Loss: 0.06589626520872116, Accuracy: 97.52166748046875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAoGJ2_RenMY",
        "colab_type": "text"
      },
      "source": [
        "##2.9. Tracking training loss across replicas\n",
        "\n",
        "We do not recommend using tf.metrics.Mean to track the training loss across different replicas, because of the loss scaling computation that is carried out. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Fa7VKqnfTF1",
        "colab_type": "text"
      },
      "source": [
        "#3. Multi-worker training with Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQWqXtAqekXl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7c2abd20-122d-4de1-d591-b6be0fafa736"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install -q tf-nightly\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "tfds.disable_progress_bar()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 519.0MB 33kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 25.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 460kB 43.1MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odan9rTCfi6r",
        "colab_type": "text"
      },
      "source": [
        "##3.1. Preparing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezEuI_mPfhSf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "1b88a637-7db4-4027-949d-11b480203cfa"
      },
      "source": [
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "def make_datasets_unbatched():\n",
        "  # Scaling MNIST data from (0, 255] to (0., 1.]\n",
        "  def scale(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image /= 255\n",
        "    return image, label\n",
        "\n",
        "  datasets, info = tfds.load(name='mnist',\n",
        "                            with_info=True,\n",
        "                            as_supervised=True)\n",
        "\n",
        "  return datasets['train'].map(scale).cache().shuffle(BUFFER_SIZE)\n",
        "\n",
        "train_datasets = make_datasets_unbatched().batch(BATCH_SIZE)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Dataset mnist is hosted on GCS. It will automatically be downloaded to your\n",
            "local data directory. If you'd instead prefer to read directly from our public\n",
            "GCS bucket (recommended if you're running on GCP), you can instead set\n",
            "data_dir=gs://tfds-data/datasets.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset mnist/3.0.0 (download: 11.06 MiB, generated: Unknown size, total: 11.06 MiB) to /root/tensorflow_datasets/mnist/3.0.0...\u001b[0m\n",
            "\u001b[1mDataset mnist downloaded and prepared to /root/tensorflow_datasets/mnist/3.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GjcOYCEfsHl",
        "colab_type": "text"
      },
      "source": [
        "##3.2. Keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD3-z6Elfpzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_and_compile_cnn_model():\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D(),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "      metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqshbkkRgrJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "a05d518b-223f-4938-d3f2-5be9d8a681b5"
      },
      "source": [
        "single_worker_model = build_and_compile_cnn_model()\n",
        "single_worker_model.fit(x=train_datasets, epochs=3, steps_per_epoch=5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 2.2879 - accuracy: 0.1063\n",
            "Epoch 2/3\n",
            "5/5 [==============================] - 0s 13ms/step - loss: 2.2889 - accuracy: 0.0844\n",
            "Epoch 3/3\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 2.2846 - accuracy: 0.0906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f97801d7f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIG5Z8Mghovn",
        "colab_type": "text"
      },
      "source": [
        "###3.2.1. Multi-worker Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTvDqZbLhZuW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['TF_CONFIG'] = json.dumps({\n",
        "    'cluster': {\n",
        "        'worker': [\"localhost:12345\", \"localhost:23456\"]\n",
        "    },\n",
        "    'task': {'type': 'worker', 'index': 0}\n",
        "})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nk2B_OEni9Fz",
        "colab_type": "text"
      },
      "source": [
        "##3.3. Choose the right strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS02VFDah49m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "726302df-cd1b-41c2-a580-cf08505e3a9a"
      },
      "source": [
        "strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/device:GPU:0',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using MirroredStrategy with devices ('/device:GPU:0',)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CollectiveCommunication.AUTO\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CollectiveCommunication.AUTO\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnP7iAWrjVmi",
        "colab_type": "text"
      },
      "source": [
        "##3.4. Train the model with MultiWorkerMirroredStrategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yc7Qt_3tjO04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "d9dbcbd6-3cd7-4c7b-caad-e5338038cae1"
      },
      "source": [
        "NUM_WORKERS = 2\n",
        "# Here the batch size scales up by number of workers since \n",
        "# `tf.data.Dataset.batch` expects the global batch size. Previously we used 64, \n",
        "# and now this becomes 128.\n",
        "GLOBAL_BATCH_SIZE = 64 * NUM_WORKERS\n",
        "\n",
        "# Creation of dataset needs to be after MultiWorkerMirroredStrategy object\n",
        "# is instantiated.\n",
        "train_datasets = make_datasets_unbatched().batch(GLOBAL_BATCH_SIZE)\n",
        "with strategy.scope():\n",
        "  # Model building/compiling need to be within `strategy.scope()`.\n",
        "  multi_worker_model = build_and_compile_cnn_model()\n",
        "\n",
        "# Keras' `model.fit()` trains the model with specified number of epochs and\n",
        "# number of steps per epoch. Note that the numbers here are for demonstration\n",
        "# purposes only and may not sufficiently produce a model with good quality.\n",
        "multi_worker_model.fit(x=train_datasets, epochs=3, steps_per_epoch=5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "5/5 [==============================] - 0s 18ms/step - loss: 2.2897 - accuracy: 0.1125\n",
            "Epoch 2/3\n",
            "5/5 [==============================] - 0s 27ms/step - loss: 2.2823 - accuracy: 0.1172\n",
            "Epoch 3/3\n",
            "5/5 [==============================] - 0s 22ms/step - loss: 2.2878 - accuracy: 0.1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f976bfab358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIVeeiTmjk8N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dataset sharding and batch size\n",
        "# In multi-worker training, sharding data into multiple parts is needed to \n",
        "# ensure convergence and performance. \n",
        "\n",
        "options = tf.data.Options()\n",
        "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF\n",
        "train_datasets_no_auto_shard = train_datasets.with_options(options)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYfzIZ5yk5FI",
        "colab_type": "text"
      },
      "source": [
        "##3.5. Fault tolerance\n",
        "\n",
        "ModelCheckpoint callback:\n",
        "\n",
        "In synchronous training, the cluster would fail if one of the workers fails and no failure-recovery mechanism exists. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3Mkn0Vvk4Ot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "d101178e-2d3f-4ef2-cb49-b4acce4be425"
      },
      "source": [
        "# Replace the `filepath` argument with a path in the file system\n",
        "# accessible by all workers.\n",
        "callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath='/tmp/keras-ckpt')]\n",
        "with strategy.scope():\n",
        "  multi_worker_model = build_and_compile_cnn_model()\n",
        "multi_worker_model.fit(x=train_datasets,\n",
        "                       epochs=3,\n",
        "                       steps_per_epoch=5,\n",
        "                       callbacks=callbacks)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "5/5 [==============================] - ETA: 0s - loss: 2.3122 - accuracy: 0.0922INFO:tensorflow:Assets written to: /tmp/keras-ckpt/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras-ckpt/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 184ms/step - loss: 2.3122 - accuracy: 0.0922\n",
            "Epoch 2/3\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.3087 - accuracy: 0.0898INFO:tensorflow:Assets written to: /tmp/keras-ckpt/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras-ckpt/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 144ms/step - loss: 2.3075 - accuracy: 0.0922\n",
            "Epoch 3/3\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 2.3117 - accuracy: 0.0781WARNING:tensorflow:5 out of the last 9 calls to <function Sequential.call at 0x7f975bdeaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 9 calls to <function Sequential.call at 0x7f975bdeaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function Sequential.call at 0x7f975bdeaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 10 calls to <function Sequential.call at 0x7f975bdeaae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please  define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras-ckpt/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/keras-ckpt/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 1s 148ms/step - loss: 2.3113 - accuracy: 0.0750\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f978028abe0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}