{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Process.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOCgW8mc3lM6",
        "colab_type": "text"
      },
      "source": [
        "#1. Load CSV data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdpPhBNsIIKu",
        "colab_type": "code",
        "outputId": "ceac5460-0efb-4865-8169-92483f571ca3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import functools\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lubuG3Yh4RlU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRAIN_DATA_URL = 'https://storage.googleapis.com/tf-datasets/titanic/train.csv'\n",
        "TEST_DATA_URL = 'https://storage.googleapis.com/tf-datasets/titanic/eval.csv'\n",
        "\n",
        "train_file_path = tf.keras.utils.get_file('train.csv', TRAIN_DATA_URL)\n",
        "test_file_path = tf.keras.utils.get_file('eval.csv', TEST_DATA_URL)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqyM18HY4tHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make numpy values easier to read\n",
        "np.set_printoptions(precision=3, suppress=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KecvvwA43im",
        "colab_type": "text"
      },
      "source": [
        "##1.1. Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZGvXFde428O",
        "colab_type": "code",
        "outputId": "0727eeaa-f609-4368-d8ae-d784d3a0640e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "!head {train_file_path}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "survived,sex,age,n_siblings_spouses,parch,fare,class,deck,embark_town,alone\n",
            "0,male,22.0,1,0,7.25,Third,unknown,Southampton,n\n",
            "1,female,38.0,1,0,71.2833,First,C,Cherbourg,n\n",
            "1,female,26.0,0,0,7.925,Third,unknown,Southampton,y\n",
            "1,female,35.0,1,0,53.1,First,C,Southampton,n\n",
            "0,male,28.0,0,0,8.4583,Third,unknown,Queenstown,y\n",
            "0,male,2.0,3,1,21.075,Third,unknown,Southampton,n\n",
            "1,female,27.0,0,2,11.1333,Third,unknown,Southampton,n\n",
            "1,female,14.0,1,0,30.0708,Second,unknown,Cherbourg,n\n",
            "1,female,4.0,1,1,16.7,Third,G,Southampton,n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijBPvh4i5AcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LABEL_COLUMN = 'survived'\n",
        "LABELS = [0, 1]\n",
        "\n",
        "# read the CSV data from the file and create a dataset\n",
        "# num_epochs: An int specifying the number of times this dataset is repeated\n",
        "def get_dataset(file_path, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path, \n",
        "      batch_size=5, # Artificially small to make examples easier to show.\n",
        "      label_name=LABEL_COLUMN,\n",
        "      na_value='?',\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True,\n",
        "      **kwargs\n",
        "  )\n",
        "  return dataset\n",
        "\n",
        "raw_train_data = get_dataset(train_file_path)\n",
        "raw_test_data = get_dataset(test_file_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgFY5Gbl8HIr",
        "colab_type": "code",
        "outputId": "3ff2f3ee-964c-413c-bcc3-33ddd221e096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "# Each item in the dataset is a batch\n",
        "# And a batch size is predefined with 5\n",
        "# take(number): representing the number of elements of this dataset that should be taken to form the new dataset. --> 1 batch 5 Elements\n",
        "def show_batch(dataset):\n",
        "  for batch, label in dataset.take(1):\n",
        "    for key, value in batch.items():\n",
        "      print('{:20s}: {}'.format(key, value.numpy()))\n",
        "\n",
        "show_batch(raw_train_data)\n",
        "# If the file you are working with does not contain the column names in the first line, pass them in a list of strings to the column_names\n",
        "# use select_columns to omit the unnessary columns"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'male' b'male' b'male' b'female']\n",
            "age                 : [20. 28. 28. 26. 38.]\n",
            "n_siblings_spouses  : [1 0 0 0 0]\n",
            "parch               : [0 0 0 0 0]\n",
            "fare                : [ 7.925  8.05  10.5   56.496 80.   ]\n",
            "class               : [b'Third' b'Third' b'Second' b'Third' b'First']\n",
            "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'B']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Southampton' b'unknown']\n",
            "alone               : [b'n' b'y' b'y' b'y' b'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeit94zi8o1X",
        "colab_type": "code",
        "outputId": "b50695f1-c2cc-4bda-b96f-a945a2c0dbbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "CSV_COLUMNS = ['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n",
        "temp_dataset = get_dataset(train_file_path, column_names=CSV_COLUMNS)\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'female' b'female' b'male' b'male' b'male']\n",
            "age                 : [25.  31.  31.  56.  40.5]\n",
            "n_siblings_spouses  : [1 0 0 0 0]\n",
            "parch               : [1 0 0 0 2]\n",
            "fare                : [30.     7.854 13.    26.55  14.5  ]\n",
            "class               : [b'Second' b'Third' b'Second' b'First' b'Third']\n",
            "deck                : [b'unknown' b'unknown' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton']\n",
            "alone               : [b'n' b'y' b'y' b'y' b'n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azP68G5C_pwq",
        "colab_type": "code",
        "outputId": "9b587436-414a-497f-bedb-808ba5cacd63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'class', 'deck', 'alone']\n",
        "temp_dataset = get_dataset(train_file_path, select_columns=SELECT_COLUMNS)\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age                 : [36. 28. 32. 11. 24.]\n",
            "n_siblings_spouses  : [1 0 0 1 0]\n",
            "class               : [b'First' b'First' b'Third' b'First' b'Third']\n",
            "deck                : [b'C' b'unknown' b'E' b'B' b'G']\n",
            "alone               : [b'n' b'y' b'y' b'n' b'n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWqwTHzG_xk6",
        "colab_type": "text"
      },
      "source": [
        "##1.2. Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXtiATWjAPTY",
        "colab_type": "text"
      },
      "source": [
        "###1.2.1. Continuous data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBf1UsEz_zUt",
        "colab_type": "code",
        "outputId": "c2396368-d3dd-465b-f47c-ddf554c29aa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# if your data is already in an appropriate numeric format, you can pack the data into a vector before passing it off to the model.\n",
        "SELECT_COLUMNS = ['survived', 'age', 'n_siblings_spouses', 'parch', 'fare']\n",
        "DEFAULTS = [0, 0.0, 0.0, 0.0, 0.0]\n",
        "temp_dataset = get_dataset(train_file_path, \n",
        "                           select_columns=SELECT_COLUMNS,\n",
        "                           column_defaults = DEFAULTS)\n",
        "\n",
        "show_batch(temp_dataset)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "age                 : [28. 59. 28. 58. 22.]\n",
            "n_siblings_spouses  : [1. 0. 1. 0. 0.]\n",
            "parch               : [0. 0. 2. 0. 0.]\n",
            "fare                : [133.65    7.25   23.45  146.521   7.896]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEp0ZqB6AkBg",
        "colab_type": "code",
        "outputId": "0b5e3412-6903-4af0-9b19-8c557326a506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "example_batch, labels_batch = next(iter(temp_dataset)) \n",
        "print(example_batch, labels_batch)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('age', <tf.Tensor: shape=(5,), dtype=float32, numpy=array([ 9. , 14.5,  2. , 29. , 32. ], dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: shape=(5,), dtype=float32, numpy=array([5., 1., 0., 1., 0.], dtype=float32)>), ('parch', <tf.Tensor: shape=(5,), dtype=float32, numpy=array([2., 0., 1., 0., 0.], dtype=float32)>), ('fare', <tf.Tensor: shape=(5,), dtype=float32, numpy=array([46.9  , 14.454, 10.462, 66.6  , 30.5  ], dtype=float32)>)]) tf.Tensor([0 0 0 0 1], shape=(5,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9bYlXGpArrW",
        "colab_type": "code",
        "outputId": "c24ff5fc-0c1c-4237-d8f1-c8b191c787da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# tf.stack stack the dataset according to the defined axis. \n",
        "def pack(features, label):\n",
        "  return tf.stack(list(features.values()), axis=-1), label\n",
        "\n",
        "packed_dataset = temp_dataset.map(pack)\n",
        "\n",
        "for features, labels in packed_dataset.take(1):\n",
        "  print(features.numpy())\n",
        "  print()\n",
        "  print(labels.numpy())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 24.      0.      0.      7.142]\n",
            " [ 18.      0.      0.      8.3  ]\n",
            " [ 38.      0.      1.    153.462]\n",
            " [ 28.      0.      0.     30.696]\n",
            " [ 28.      0.      2.      7.75 ]]\n",
            "\n",
            "[1 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMKS5Ud7CXLw",
        "colab_type": "code",
        "outputId": "45cc3e96-e2e2-4642-9a97-1695240fca15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# tf.feature_column can handle mixed datatypes, but this incurs some overhead and \n",
        "# should be avoided unless really necessary\n",
        "show_batch(raw_train_data)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'male' b'male' b'male' b'male']\n",
            "age                 : [34. 64. 17. 27. 42.]\n",
            "n_siblings_spouses  : [0 1 0 0 1]\n",
            "parch               : [0 4 0 0 0]\n",
            "fare                : [ 26.55  263.      8.663   7.896  27.   ]\n",
            "class               : [b'First' b'First' b'Third' b'Third' b'Second']\n",
            "deck                : [b'unknown' b'C' b'unknown' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton']\n",
            "alone               : [b'y' b'n' b'y' b'y' b'n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc-Uk-1kB_gO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_batch, labels_batch = next(iter(temp_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ERn6dJKCJmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# So define a more general preprocessor that selects a list of numeric features\n",
        "# and packs them into a single column\n",
        "class PackNumericFeatures(object):\n",
        "  def __init__(self, names):\n",
        "    self.names = names\n",
        "\n",
        "  def __call__(self, features, labels):\n",
        "    numeric_features = [features.pop(name) for name in self.names]\n",
        "    # casts x (Tensor), x.values (SparseTensor, IndexedSlices) to dtype\n",
        "    numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "    numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "    features['numeric'] = numeric_features\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "# __init__(): is used to initialise newly created object\n",
        "# class Foo:\n",
        "#   def __init__(self, a, b, c): ...\n",
        "# x = Foo(1, 2, 3)\n",
        "\n",
        "# __call__(): implements function call operator\n",
        "# class Foo:\n",
        "#   def __call__(self, a, b, c): ...\n",
        "# x = Foo()\n",
        "# x(1, 2, 3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhKKJCpTFPTb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUMERIC_FEATURES = ['age','n_siblings_spouses','parch', 'fare']\n",
        "\n",
        "packed_train_data = raw_train_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "packed_test_data = raw_test_data.map(\n",
        "    PackNumericFeatures(NUMERIC_FEATURES))\n",
        "\n",
        "# tf.data.Dataset.map(map_func, num_parallel_calls=None)\n",
        "# This transformation applies map_func to each element of this dataset, and\n",
        "# returns a new dataset containing the transformed elements.\n",
        "# num_parallel_calls: A tf.int32 scalar tf.Tensor, representing the number elements\n",
        "# to process asynchronously in parallel. If not specified, elements will be processed sequentially.  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhJDtYCNH-Xk",
        "colab_type": "code",
        "outputId": "6588b149-9ff0-4852-97a0-75121deb3d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "show_batch(packed_train_data)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                 : [b'male' b'male' b'male' b'female' b'male']\n",
            "class               : [b'Second' b'Third' b'First' b'Second' b'Second']\n",
            "deck                : [b'unknown' b'unknown' b'C' b'unknown' b'unknown']\n",
            "embark_town         : [b'Southampton' b'Southampton' b'Southampton' b'Southampton'\n",
            " b'Southampton']\n",
            "alone               : [b'y' b'y' b'n' b'y' b'y']\n",
            "numeric             : [[ 16.     0.     0.    10.5 ]\n",
            " [ 21.     0.     0.     8.05]\n",
            " [ 19.     3.     2.   263.  ]\n",
            " [ 35.     0.     0.    21.  ]\n",
            " [ 35.     0.     0.    10.5 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f7kgB4RIXLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "example_batch, labels_batch = next(iter(packed_train_data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwaapk1oPzDt",
        "colab_type": "text"
      },
      "source": [
        "###1.2.2. Data Normalization for numerical data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGC3Vt7YPr6v",
        "colab_type": "code",
        "outputId": "3416636f-d487-4b3e-9ef6-5143c62e6a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "# Continuous data should always be normalized.\n",
        "import pandas as pd\n",
        "desc = pd.read_csv(train_file_path)[NUMERIC_FEATURES].describe()\n",
        "desc"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>n_siblings_spouses</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "      <td>627.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.631308</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>0.379585</td>\n",
              "      <td>34.385399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>12.511818</td>\n",
              "      <td>1.151090</td>\n",
              "      <td>0.792999</td>\n",
              "      <td>54.597730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>23.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>7.895800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>15.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>35.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>31.387500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>80.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>512.329200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              age  n_siblings_spouses       parch        fare\n",
              "count  627.000000          627.000000  627.000000  627.000000\n",
              "mean    29.631308            0.545455    0.379585   34.385399\n",
              "std     12.511818            1.151090    0.792999   54.597730\n",
              "min      0.750000            0.000000    0.000000    0.000000\n",
              "25%     23.000000            0.000000    0.000000    7.895800\n",
              "50%     28.000000            0.000000    0.000000   15.045800\n",
              "75%     35.000000            1.000000    0.000000   31.387500\n",
              "max     80.000000            8.000000    5.000000  512.329200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAOLNbOwQKGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MEAN = np.array(desc.T['mean'])\n",
        "STD = np.array(desc.T['std'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1NKoD1WQ3dU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_numeric_data(data, mean, std):\n",
        "  # Center the data\n",
        "  return (data-mean)/std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhC7YBmSRFF_",
        "colab_type": "code",
        "outputId": "dfec4208-2401-4e83-be01-786d8f1efd1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Partial functions allow us to fix a certain number of arguments of \n",
        "# a function and generate a new function. \n",
        "\n",
        "# functools.partial calls normalize_numeric function, with mean=MEAN, and std=STD\n",
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "\n",
        "# Represents real valued or numerical features Returns: A NumericColumn\n",
        "numeric_column = tf.feature_column.numeric_column('numeric', normalizer_fn=normalizer, shape=[len(NUMERIC_FEATURES)])\n",
        "numeric_columns = [numeric_column]\n",
        "numeric_column"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NumericColumn(key='numeric', shape=(4,), default_value=None, dtype=tf.float32, normalizer_fn=functools.partial(<function normalize_numeric_data at 0x7f796a8f82f0>, mean=array([29.631,  0.545,  0.38 , 34.385]), std=array([12.512,  1.151,  0.793, 54.598])))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQDCN5uRR_4y",
        "colab_type": "code",
        "outputId": "df98b069-fbb0-48f9-94fe-39a679294e17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# When you train the model, include this feature column to select and center this block of numeric data\n",
        "example_batch['numeric']"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[28.   ,  1.   ,  0.   , 82.171],\n",
              "       [39.   ,  0.   ,  0.   , 26.   ],\n",
              "       [39.   ,  0.   ,  0.   , 24.15 ],\n",
              "       [ 4.   ,  3.   ,  2.   , 27.9  ],\n",
              "       [28.   ,  0.   ,  0.   ,  7.55 ]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLzjIaPdVEUh",
        "colab_type": "code",
        "outputId": "5d13e6c8-cfdb-4cd3-cdb0-2fa874bf598c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# A layer that produces a dense Tensor based on given feature_columns\n",
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "numeric_layer(example_batch).numpy()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.13 ,  0.395, -0.479,  0.875],\n",
              "       [ 0.749, -0.474, -0.479, -0.154],\n",
              "       [ 0.749, -0.474, -0.479, -0.187],\n",
              "       [-2.049,  2.132,  2.043, -0.119],\n",
              "       [-0.13 , -0.474, -0.479, -0.492]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHoZkorqvB2I",
        "colab_type": "text"
      },
      "source": [
        "###1.2.3. One-hot exchange for categorical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhMFMof0VYL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one-hot for categorical data\n",
        "CATEGORIES = {\n",
        "    'sex': ['male', 'female'],\n",
        "    'class' : ['First', 'Second', 'Third'],\n",
        "    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
        "    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
        "    'alone' : ['y', 'n']\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CPYC44LtoDc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "07fb75e3-d7cb-4223-a17f-9a8f63cec7a9"
      },
      "source": [
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "  cat_col = tf.feature_column.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab)\n",
        "  categorical_columns.append(tf.feature_column.indicator_column(cat_col))\n",
        "categorical_columns"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='class', vocabulary_list=('First', 'Second', 'Third'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='deck', vocabulary_list=('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='embark_town', vocabulary_list=('Cherbourg', 'Southhampton', 'Queenstown'), dtype=tf.string, default_value=-1, num_oov_buckets=0)),\n",
              " IndicatorColumn(categorical_column=VocabularyListCategoricalColumn(key='alone', vocabulary_list=('y', 'n'), dtype=tf.string, default_value=-1, num_oov_buckets=0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKGGQZ30uG9U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "24d0db31-295e-4b9a-80ce-edee673d65c6"
      },
      "source": [
        "categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "print(categorical_layer(example_batch).numpy()[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnz3K6wtvII3",
        "colab_type": "text"
      },
      "source": [
        "###1.2.4. Combined preprocessing data (Layer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmbPsNxHuMqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5b5ff647-6af4-4a52-c3f9-4c279a3ac114"
      },
      "source": [
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)\n",
        "print(preprocessing_layer(example_batch).numpy()[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0.     1.     1.     0.     0.     0.     0.     0.     0.     0.\n",
            "  0.     0.     0.     0.     0.     1.     0.     0.    -0.13   0.395\n",
            " -0.479  0.875  0.     1.   ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXXPhkEMvhvg",
        "colab_type": "text"
      },
      "source": [
        "##1.3. Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wptsXvzfvZg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    preprocessing_layer,\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmwM_lRfv7ea",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "11ae271d-9ebb-48e0-de82-f7a673758422"
      },
      "source": [
        "# Train, evaluate, and predict\n",
        "train_data = packed_train_data.shuffle(500)\n",
        "test_data = packed_test_data\n",
        "model.fit(train_data, epochs=20)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7544\n",
            "Epoch 2/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.4194 - accuracy: 0.8278\n",
            "Epoch 3/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.4034 - accuracy: 0.8166\n",
            "Epoch 4/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3897 - accuracy: 0.8437\n",
            "Epoch 5/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8293\n",
            "Epoch 6/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3694 - accuracy: 0.8469\n",
            "Epoch 7/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3592 - accuracy: 0.8453\n",
            "Epoch 8/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3557 - accuracy: 0.8533\n",
            "Epoch 9/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8469\n",
            "Epoch 10/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8565\n",
            "Epoch 11/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3337 - accuracy: 0.8533\n",
            "Epoch 12/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8565\n",
            "Epoch 13/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8644\n",
            "Epoch 14/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8565\n",
            "Epoch 15/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8692\n",
            "Epoch 16/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8596\n",
            "Epoch 17/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8628\n",
            "Epoch 18/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3080 - accuracy: 0.8724\n",
            "Epoch 19/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8708\n",
            "Epoch 20/20\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7969d93240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2iEh8yawJKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b7a2308f-9f69-4e60-a777-497f71724ae3"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.8447\n",
            "\n",
            "\n",
            "Test Loss 0.4718002378940582, Test Accuracy 0.8446969985961914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rv4NzptwSbk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "9fc5bc62-7371-4af2-f2b9-e92b0ee19b08"
      },
      "source": [
        "predictions = model.predict(test_data)\n",
        "print(predictions[:10])\n",
        "# Show some results\n",
        "for prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\n",
        "  prediction = tf.sigmoid(prediction).numpy()\n",
        "  print(\"Predicted survival: {:.2%}\".format(prediction[0]),\n",
        "        \" | Actual outcome: \",\n",
        "        (\"SURVIVED\" if bool(survived) else \"DIED\"))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.372]\n",
            " [-0.307]\n",
            " [-0.965]\n",
            " [ 3.122]\n",
            " [-6.683]\n",
            " [-1.404]\n",
            " [10.205]\n",
            " [ 2.908]\n",
            " [-0.965]\n",
            " [ 0.522]]\n",
            "Predicted survival: 20.23%  | Actual outcome:  SURVIVED\n",
            "Predicted survival: 42.39%  | Actual outcome:  DIED\n",
            "Predicted survival: 27.60%  | Actual outcome:  DIED\n",
            "Predicted survival: 95.78%  | Actual outcome:  DIED\n",
            "Predicted survival: 0.13%  | Actual outcome:  DIED\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4wwBfU6w6W-",
        "colab_type": "text"
      },
      "source": [
        "#2. Load NumPy Data\n",
        "\n",
        "loading data from NumPy arrays into a tf.data,Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAcGEzyawh7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0Wv3JHlxzh0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "060df025-a148-4be8-9879-03a43d0d4b2b"
      },
      "source": [
        "DATA_URL = 'https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz'\n",
        "\n",
        "path = tf.keras.utils.get_file('mnist.npz', DATA_URL)\n",
        "# np.load: .npy, .npz\n",
        "with np.load(path) as data:\n",
        "  train_examples = data['x_train']\n",
        "  train_labels = data['y_train']\n",
        "  test_examples = data['x_test']\n",
        "  test_labels = data['y_test']"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX6CtiZiyd6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load NumPy arrays with tf.data.Dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_examples, test_labels))\n",
        "# return a tf.data.Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I91-Wxu4yynt",
        "colab_type": "text"
      },
      "source": [
        "##2.1. Use the datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPIXrhD5yxtA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "SHUFFLE_BUFFER_SIZE = 100\n",
        "\n",
        "# A batch contains 64 elements/objects\n",
        "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvA9vCtq1MMK",
        "colab_type": "text"
      },
      "source": [
        "##2.2. Build and Train a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJBLGTRg1Inr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "0decd2cc-1afe-41d0-80ad-441048f9b0a3"
      },
      "source": [
        "model = tf.keras.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Flatten(input_shape=(28, 28)), \n",
        "     tf.keras.layers.Dense(128, activation='relu'),\n",
        "     tf.keras.layers.Dense(10)\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(train_dataset, epochs=10)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 3.1503 - sparse_categorical_accuracy: 0.8766\n",
            "Epoch 2/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.5315 - sparse_categorical_accuracy: 0.9267\n",
            "Epoch 3/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.3961 - sparse_categorical_accuracy: 0.9445\n",
            "Epoch 4/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.3264 - sparse_categorical_accuracy: 0.9519\n",
            "Epoch 5/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2921 - sparse_categorical_accuracy: 0.9588\n",
            "Epoch 6/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2686 - sparse_categorical_accuracy: 0.9620\n",
            "Epoch 7/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2343 - sparse_categorical_accuracy: 0.9670\n",
            "Epoch 8/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2198 - sparse_categorical_accuracy: 0.9686\n",
            "Epoch 9/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.2075 - sparse_categorical_accuracy: 0.9714\n",
            "Epoch 10/10\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 0.1966 - sparse_categorical_accuracy: 0.9742\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7965e066a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9uD3VIo1uSu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cbf0d211-68af-429c-ca2c-5d996e544148"
      },
      "source": [
        "model.evaluate(test_dataset)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 1ms/step - loss: 0.6510 - sparse_categorical_accuracy: 0.9531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6510223150253296, 0.9531000256538391]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbCXXfmc18cB",
        "colab_type": "text"
      },
      "source": [
        "#3. Load a pandas.DataFrame\n",
        "\n",
        "loading pandas dataframes into tf.data.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6-SYiAh12wb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}